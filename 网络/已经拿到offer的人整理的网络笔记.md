# 计算机网络面经（前端）

## 5.1 URL加载的过程

1）首先，在浏览器地址栏中输入url

​		如果为非url结构的字符串，交给浏览器默认引擎去搜索改字符串；若为url结构的字符串，浏览器主进程会交给 网络进程，开始干活。

2）浏览器先查看浏览器缓存-系统缓存-路由器缓存，如果缓存中有，会直接在屏幕中显示页面内容。若没有，则跳到第三步操作。

​		网络进程会先看看是否存在本地缓存，如果有就直接返回资源给浏览器进程，无则下一步 DNS-> IP -> TCP。

3）在发送http请求前，需要域名解析(DNS解析)，解析获取相应的IP地址。

​		网络进程拿到url后，先会进行DNS域名解析得到IP地址。如果请求协议是HTTPS，那么还需要建立TLS连接。

4）浏览器向服务器利用IP地址和服务器建立TCP连接。，与浏览器建立tcp三次握手。

5）握手成功后，浏览器向服务器发送http请求，请求数据包。

连接建立之后，向服务器发送请求。服务器收到请求信息后，会根据请求信息生成响应行、响应头、响应体，并发给网络进程。网络进程接受了响应信息之后，就开始解析响应头的内容。

6）服务器处理收到的请求，将数据返回至浏览器

​		默认情况，每个页面一个渲染进程。但若处于同一站点（同根域名+协议），那么渲染进程就会复用。

7）浏览器收到HTTP响应

8）读取页面内容，浏览器渲染，解析html源码

​		渲染进程准备好后，浏览器进程发出“提交文档的消息”，渲染进程接受了消息之后，会跟网络进程简历传输数据的管道。等数据传输完成了，渲染进程会告诉浏览器进程，确认文档提交，这时候浏览器会更新页面，安全状态，url，前进后退的历史。

9）渲染进程接受到数据，生成Dom树、解析css样式、js交互,渲染显示页面。

​		同步构建DOM树和CSSOM树，当CSSOM生成结束执行js。浏览器会先从DOM树的根节点开始遍历每个可见节点，并把这些节点添加到渲染树中。不可见的节点不会添加到渲染树，比如css设置了display为none 属性的节点。根据生成的渲染树，进行布局（也可以叫做回流），得到各个节点在页面中的确切位置和大小。生成分层树，页面都是一层一层叠加在一起形成的。比如一些复杂的css动画，z-index等，渲染引擎会为他们生成专用的图层，并生成对应的图层树。

## 5.2 Http

### 5.2.1 发展

| 0.9  | html文件传输           | 确定了客户端请求，服务器响应的通信流程 |
| ---- | ---------------------- | -------------------------------------- |
| 1.0  | 不同类型文件传输       | 设立头部字段                           |
| 1.1  | 创建/断开TCP连接开销大 | 建立长连接进行复用                     |
| 2    | 并发数有限             | 二进制分帧                             |
| 3    | TCP丢包阻塞            | 采用UDP协议                            |

**对头阻塞：**

​		头部阻塞是 TCP中的一个问题，当一个 TCP 流中的一个数据包丢失时，整个流都会被阻塞，直到丢失的数据包被重新发送和接收。HTTP/1.1 时代建立一个 TCP 连接，三个请求组成一个队列发出去，服务器接收到这个队列之后会依次响应，一旦前面的请求阻塞，后面的请求就会无法响应。

​		HTTP/2 并没有解决 TCP 的队首阻塞问题，它仅仅是通过**多路复用**解决了以前 HTTP1.1 **管线化**请求时的队首阻塞。HTTP/2 是通过**分帧**并且给每个帧打上**流**的 ID 去避免依次响应的问题，对方接收到帧之后根据 ID 拼接出流，这样就可以做到乱序响应从而避免请求时的队首阻塞问题。但是 TCP 层面的队首阻塞是 HTTP/2 无法解决的（HTTP 只是应用层协议，TCP 是传输层协议），TCP 的阻塞问题是因为传输阶段可能会丢包，一旦丢包就会等待重新发包，阻塞后续传输，这个问题虽然有**滑动窗口（Sliding Window）**这个方案，但是只能增强抗干扰，并没有彻底解决。

​		HTTP/3 通过使用基于 UDP 的 QUIC 协议来解决这个问题。在 QUIC 中，流是独立的，如果一个流中的数据包丢失，它不会影响其他的流。这就意味着，即使在一个流中发生了数据包丢失，其他的流仍然可以继续传输数据。这样就消除了头部阻塞问题。

**长连接与管道：**

​		在 HTTP/0.9 版本中，HTTP 请求是以短连接进行的，因此在发送完 HTTP 的响应之后，服务器就会断开 TCP 连接。可是这样是一件很耗资源、很耗时间的事情，所以在 1.0 版本中，新增了 keep-alive 字段，让长连接被 HTTP 支持了（此时默认还是不会开启长连接）。所谓长连接，就是完成这个 HTTP 请求之后，不要断开 HTTP 请求使用的 TCP 连接。好处是连接可以被重新使用，之后发送 HTTP 请求的时候就不需要重新建立 TCP 连接了，以及如果维持连接，那么 SSL 的开销也可以避免。

好处如此之多，所以 HTTP/1.1 就把 Connection: keep-alive 头写进了标准，并且默认开启持久连接(两小时，心跳检测 5次)。

必须在请求中声明：Connection: close 才会让每次 HTTP 请求都重新建立 TCP 连接。

- 如果是「短连接」，那么一次 TCP 连接就只能对应一次 HTTP 请求；
- 如果是「长连接」，那么一次 TCP 连接就可以发送多个 HTTP 请求了。

管道是 HTTP/1.1 规范中的字段，能将多个 HTTP 请求整批提交，在发送过程中不需先等待服务器的回应。因为该技术存在很多问题：

1. 一些代理服务器不能正确的处理 HTTP Pipelining；
2. 正确的流水线实现是复杂的；
3. Head-of-line Blocking 连接头阻塞：在建立起一个 TCP 连接之后，假设客户端在这个连接连续向服务器发送了几个请求。按照标准，服务器应该按照收到请求的顺序返回结果，假设服务器在处理首个请求时花费了大量时间，那么后面所有的请求都需要等着首个请求结束才能响应。

HTTP2 提供了 Multiplexing 多路传输特性，让我们可以在一个 TCP 连接中同时完成多个 HTTP 请求。（可以将数据拆成包，给每个包打上标签。到了服务器在进行拼接即可，本质上还是管道）

连接上限：

​		浏览器允许我们对同一 host 开启多个 TCP 连接，每个浏览器的数量是不一样的。Chrome 最多允许对同一个 Host 建立六个 TCP 连接。

​	**Http和Https的区别：**

​		HTTP协议也就是超文本传输协议，是一种使用明文数据传输的网络协议。一直以来HTTP协议都是最主流的网页协议，HTTP协议被用于在Web浏览器和网站服务器之间传递信息，以明文方式发送内容，不提供任何方式的数据加密，如果攻击者截取了Web浏览器和网站服务器之间的传输报文，就可以直接读懂其中的信息。

​		为了解决HTTP协议的这一缺陷，需要使用另一种协议：安全套接字层超文本传输协议HTTPS，为了数据传输的安全，HTTPS在HTTP的基础上加入了SSL/TLS协议，SSL/TLS依靠证书来验证服务器的身份，并为浏览器和服务器之间的通信加密。HTTPS协议可以理解为HTTP协议的升级，就是在HTTP的基础上增加了数据加密。在数据进行传输之前，对数据进行加密，然后再发送到服务器。这样，就算数据被第三者所截获，但是由于数据是加密的，所以你的个人信息仍然是安全的。

​		具体过程为：客户端发起 SSL orTLS握手 -> 服务端将证书发送给客户端 -> 客户端检查是否为 CA （双方约定可信任证书签发机构）-> 服务端检查客户端 CA 证书 ；

**Http2和Http3区别：**

​		HTTP2协议虽然大幅提升了HTTP/1.1的性能，然而，基于TCP实现的HTTP2遗留下3个问题：

- 有序字节流引出的队头阻塞（Head-of-line blocking），使得HTTP2的多路复用能力大打折扣；
- TCP与TLS叠加了握手时延，建链时长还有1倍的下降空间；
- 基于TCP四元组确定一个连接，这种诞生于有线网络的设计，并不适合移动状态下的无线网络，这意味着IP地址的频繁变动会导致TCP连接、TLS会话反复握手，成本高昂。

​		HTTP3协议解决了这些问题：

- HTTP3基于UDP协议重新定义了连接，在QUIC层实现了无序、并发字节流的传输，解决了队头阻塞问题（包括基于QPACK解决了动态表的队头阻塞）；
- HTTP3重新定义了TLS协议加密QUIC头部的方式，既提高了网络攻击成本，又降低了建立连接的速度（仅需1个RTT就可以同时完成建链与密钥协商）；
- HTTP3 将Packet、QUIC Frame、HTTP3 Frame分离，实现了连接迁移功能，降低了5G环境下高速移动设备的连接维护成本。

**Https发展**

背景：早期的数据在网络传输中使用的http协议，这种协议采取的是明文传输的方式。从一个结点到另一个结点传输的过程中会存在一些不法分子从中窃取信息。早起的运营商也会利用职务之便进行数据劫持，在web里插入代码显示广告。在20世纪90年代中期，当人们意识到互联网应用越来越广泛，所传递的信息价值越来越高时，便不得不考虑对网络进行安全性处理。最早吃螃蟹的是当时最大的网景公司，在1994年对**http1.1**进行了升级。https发展:最早采用的方法便是加密，加密和解密采用相同的密钥，如凯撒加密，恩格码机等，这种加密方式就是对称加密。但是要想让传输双方进行解密，那在传递的过程中需要把密钥一起传递，这种加密方式就失去了意义。于是产生了非对称加密，利用公钥和私钥。服务器先将自己的公钥发送给浏览器。浏览器生成一个随机的数据，用服务器的公钥加密然后发送给服务器，服务器利用自己的私钥进行解密，于是就产生了一份相同的数据。这份数据用作双方传递的密钥进行加密传输。这是一套独立于http协议的流程，被称为安全套接字层（secure socket layer-ssl）后来ssl进行了三次升级，最后一次升级后被冠以TSL进行正式发布。所以TSL1.0也被叫做ssl3.1。升级过程是对加密方式的升级，比如舍弃了md5采用sha-256。但是如果有人将服务器传递给浏览器的公钥进行窃取然后更换成自己的公钥发送给浏览器，依旧会存在安全性问题。因此引入了CA的概念，ca会进行第三方加密以验证服务器身份，这就是TsL证书。这些ca机构会被保存在客户端本地以供浏览器需要。前几年有些网站自己给自己颁发证书，会存在不被认可的问题，12306。但是ca机构的权利过于集中，一旦ca机构出现问题，导致的问题不可估量。比如google和赛门铁克，还有棱镜门利用虚假的证书来窃听用户隐私。因此，引入了证书透明化，ct。但是这种套娃的操作并不能很好的解决该类问题。因此我认为去中心化才是核心。区块链给人们最大的启示就是任何中心化的技术都是不被信任的，无论他如何权威。ct中的日志服务采用了区块链中的默克尔树进行防篡改实现。这是一种类似于归并去计算每一层hash的方法，将根hash保存在每一个客户端上。

**HTTPS 握手过程中，客户端如何验证证书的合法性**

```
校验证书的颁发机构是否受客户端信任。
2. 通过 CRL 或 OCSP 的方式校验证书是否被吊销。
3. 对比系统时间，校验证书是否在有效期内。
4. 通过校验对方是否存在证书的私钥，判断证书的网站域名是否与证书颁发的域名一致。
证书包含：公钥、公钥拥有者名称、CA的数字签名、有效期、授权中心名称、证书序列号等信息。
```

**怎么通过数字证书验证服务器身份**

1. 客户端发起连接请求：客户端向服务器发起连接请求，例如使用HTTPS协议访问一个网站。

ssl握手过程中，浏览器会通过证书链层层验证，直至操作系统上的根证书，根证书存储在客户端本地【`C:\Windows\System32`】，其余的存储在服务器上。

1. 服务器发送数字证书：服务器将其数字证书发送给客户端。数字证书是由可信任的证书颁发机构（CA）颁发的，其中包含了服务器的公钥以及其他相关信息。
2. 客户端验证数字证书的合法性：客户端会使用内置的根证书颁发机构列表（或者操作系统提供的信任存储）来验证服务器发送的数字证书的合法性。客户端会检查证书的签名是否有效、证书是否过期、证书是否被吊销等。

以下三步：向服务器发送一个随机数，从证书中获取服务器端的公钥，对随机数加密；编码改变通知，表示随后信息都将使用双方协定的加密方法和密钥发送；客户端握手结束通知。

1. 公钥提取：如果数字证书通过验证，客户端会从证书中提取出服务器的公钥。
2. 生成随机密钥：客户端会生成一个随机的对称密钥，用于加密通信过程中的数据。
3. 使用服务器的公钥加密对称密钥：客户端使用服务器的公钥对随机生成的对称密钥进行加密，然后将加密后的对称密钥发送给服务器。

服务器端对数据解密得到随机数，发送消息：编码改变通知，表示随后信息都将使用双方协定的加密方法和密钥发送。

1. 服务器使用私钥解密对称密钥：服务器使用自己的私钥解密收到的加密对称密钥。
2. 建立加密通道：客户端和服务器双方现在都拥有相同的对称密钥，它们可以使用该密钥来进行加密和解密通信内容，建立安全的加密通道。

​	**SSL和TLS区别：**

SSL：（Secure Socket Layer，安全套接字层），位于可靠的面向连接的网络层协议和应用层协议之间的一种协议层。SSL通过互相认证、使用数字签名确保完整性、使用加密确保私密性，以实现客户端和服务器之间的安全通讯。该协议由两层组成：SSL记录协议和SSL握手协议。

TLS：(Transport Layer Security，传输层安全协议)，用于两个应用程序之间提供保密性和数据完整性。该协议由两层组成：TLS记录协议和TLS握手协议。

SSL协议提供的服务主要有：

1）认证用户和服务器，确保数据发送到正确的客户机和服务器；

2）加密数据以防止数据中途被窃取；

3）维护数据的完整性，确保数据在传输过程中不被改变。

TLS 记录协议提供的连接安全性具有两个基本特性：

​		私有――对称加密用以数据加密（DES 、RC4 等）。对称加密所产生的密钥对每个连接都是唯一的，且此密钥基于另一个协议（如握手协议）协商。记录协议也可以不加密使用。



​		可靠――信息传输包括使用密钥的MAC进行信息完整性检查。安全哈希功能（ SHA、MD5 等）用于 MAC 计算。记录协议在没有 MAC 的情况下也能操作，但一般只能用于这种模式，即有另一个协议正在使用记录协议传输协商安全参数。

![img](D:/%E6%96%87%E4%BB%B6/typora%E5%9B%BE%E7%89%87/v2-0a145c61756af47c470679edd400d390_720w.webp)

参考：

- HTTP发展史，HTTP1.1与HTTP2.0的区别  https://juejin.cn/post/7079936383925616653
- https://www.cnblogs.com/xhyccc/p/14392670.html
- https://segmentfault.com/q/1010000005167289

### 5.2.2 请求｜Option

1 客户端请求消息**客户端发送一个HTTP请求到服务器的请求消息包括以下格式：请求行（request line）、请求头部（header）、空行和请求数据四个部分组成。

```js
GET /hello.txt HTTP/1.1
//HTTP1.0 定义了三种请求方法： GET, POST 和 HEAD 方法。
//HTTP1.1 新增了六种请求方法：OPTIONS、PUT、PATCH、DELETE、TRACE 和 CONNECT 方法。
User-Agent: curl/7.16.3 libcurl/7.16.3 OpenSSL/0.9.7l zlib/1.2.3
Host: www.example.com
Accept-Language: en, mi
```

**request header**

1.Accept

作用： 浏览器端可以接受的媒体类型, 例如： Accept: text/html 代表浏览器可以接受服务器回发的类型为 text/html 也就是我们常说的html文档,如果服务器无法返回text/html类型的数据,服务器应该返回一个406错误(non acceptable)

2.Accept-Encoding：

作用： 浏览器申明自己接收的编码方法，通常指定压缩方法，是否支持压缩，支持什么压缩方法（gzip，deflate），（注意：这不是只字符编码）; 例如： Accept-Encoding: zh-CN,zh;q=0.8

4.Connection

Connection: keep-alive 当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接

8.Cache-Control

Cache-Control与Expires的作用一致，都是指明当前资源的有效期，控制浏览器是否直接从浏览器缓存取数据还是重新发请求到服务器取数据。

**2 服务器响应消息**HTTP响应也由四个部分组成，分别是：状态行、消息报头、空行和响应正文。

```js
HTTP/1.1 200 OK
// 当前的GMT时间。
Date: Mon, 27 Jul 2009 12:28:53 GMT
//服务器名字。Servlet一般不设置这个值，而是由Web服务器自己设置。
Server: Apache
//文档的最后改动时间。
Last-Modified: Wed, 22 Jul 2009 19:15:56 GMT
// 指纹，比较两次请求是否变化，允许缓存更有效并节省带宽
ETag: "34aa387-d-1568eb00"
Accept-Ranges: bytes
//表示内容长度。只有当浏览器使用持久HTTP连接时才需要这个数据。
Content-Length: 51
//过期时间
Expires：
Set-cookie:
Vary: Accept-Encoding
//用于定义网络文件的类型和网页的编码:
//text/html ： HTML格式 /plain ：纯文本格式 /xml ： XML格式 /png：png图片格式
//application/xhtml+xml ：XHTML格式 /json： JSON数据格式 /pdf：pdf格式
Content-Type: text/plain //Content-Type 标头告诉客户端实际返回的内容的内容类型。一般是指网页中存在的 Content-Type，用于定义网络文件的类型和网页的编码，决定浏览器将以什么形式、什么编码读取这个文件，这就是经常看到一些 PHP 网页点击的结果却是下载一个文件或一张图片的原因。
/*
text/html ： HTML格式
text/plain ：纯文本格式
text/xml ： XML格式
image/jpeg ：jpg图片格式 png gif图片格式
application/xhtml+xml ：XHTML格式
application/xml： XML数据格式
application/atom+xml ：Atom XML聚合格式
application/json： JSON数据格式
application/pdf：pdf格式
application/msword ： Word文档格式
application/octet-stream ： 二进制流数据（如常见的文件下载）
*/
```

**response header**

1.刷新和延时跳转

一秒刷新页面一次 response.setHeader(“refresh”,“1”);

二秒跳到其他页面 response.setHeader(“refresh”,“2;URL=otherPagename”);

2.没有缓存

response.setHeader(“Pragma”, “No-cache”);

response.setHeader(“Cache-Control”, “no-cache”);

3.设置过期的时间期限

response.setDateHeader(“Expires”, System.currentTimeMillis()+自己设置的时间期限);

4.设置请求文件最后修改时间

response.setDateHeader(“Last-Modified”, System.currentTimeMillis());

5.访问别的页面(重定向)

response.setStatus（302）;

response.setHeader(“location”,“url”);

**3 OPTIONS**

在CORS机制一个域名A要访问域名B的服务，在一些特殊的复杂请求下（简单请求并不会进行预请求），浏览器必须先使用OPTIONS请求进行一个预检请求（preflight request）来获取B服务是否允许跨域请求，服务进行确认之后，才会发起真正的HTTP请求。在预检请求的返回中，服务器端也可以通知客户端，是否需要携带身份凭证（包括 Cookies 和 HTTP 认证相关数据）。

简单请求：

1. http方法是以下之一：GET | HEAD | POST
2. HTTP的头信息不超出以下几种字段：

- Accept
- Accept-Language | Content-Language
- Content-Type （需要注意额外的限制）

1. Content-Type 的值为 text/plain

请求情况：

- withCredentials为true不会产生预请求
- 请求头Content-Type为application/json会产生预请求
- 设置了用户自定义请求头会产生预检请求
- delete方法产生预检请求

**预检请求不一定每一次都会产生**

这个因为浏览器会对预检请求进行缓存，同时通过服务器端设置 Access-Control-Max-Age 字段来设置缓存时间。

那么当第一次请求该 URL 时会发出 OPTIONS 请求，浏览器会根据返回的 Access-Control-Max-Age 字段缓存该请求的 OPTIONS 预检请求的响应结果。

### 5.2.3 请求方法

**以资源为基础** ：资源可以是一个图片、音乐、一个XML格式、HTML格式或者JSON格式等网络上的一个实体，除了一些二进制的资源外普通的文本资源更多以JSON为载体、面向用户的一组数据(通常从数据库中查询而得到)。**统一接口**: 对资源的操作包括获取、创建、修改和删除，这些操作正好对应HTTP协议提供的GET、POST、PUT和DELETE方法。换言而知，使用RESTful风格的接口但从接口上你可能只能定位其资源，但是无法知晓它具体进行了什么操作，需要具体了解其发生了什么操作动作要从其HTTP请求方法类型上进行判断。具体的HTTP方法和方法含义如下：

- GET（SELECT）：从服务器取出资源（一项或多项）。
- POST（CREATE）：在服务器新建一个资源。
- PUT（UPDATE）：在服务器更新资源（客户端提供完整资源数据）。
- PATCH（UPDATE）：在服务器更新资源（客户端提供需要修改的资源数据）。
- DELETE（DELETE）：从服务器删除资源。

**URI指向资源**：URI = Universal Resource Identifier 统一资源标志符，用来标识抽象或物理资源的一个紧凑字符串。URI包括URL和URN，在这里更多时候可能代指URL(统一资源定位符)。RESTful是面向资源的，每种资源可能由一个或多个URI对应，但一个URI只指向一种资源。

**无状态**：服务器不能保存客户端的信息， 每一次从客户端发送的请求中，要包含所有必须的状态信息，会话信息由客户端保存， 服务器端根据这些状态信息来处理请求。 当客户端可以切换到一个新状态的时候发送请求信息， 当一个或者多个请求被发送之后, 客户端就处于一个状态变迁过程中。 每一个应用的状态描述可以被客户端用来初始化下一次的状态变迁。

**其他方法：**

CONNECT	HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器。OPTIONS	HTTP1.1 允许客户端查看服务器的性能。TRACE	HTTP1.1 回显服务器收到的请求，主要用于测试或诊断。PATCH	HTTP1.1 是对 PUT 方法的补充，用来对已知资源进行局部更新 。

**post一定安全吗？**

​		只要拦截到了传递的数据体，用户名和密码就能轻松获取。MD5是一种常用的加密方法，它是一种散列函数，利用MD5对用户信息进行加密，会增加用户信息安全性。但是依旧可以利用一些方法破解(cmd5网)，因此可以在此之上加盐，在密码后面接一组乱码同时加密

**幂等性**

​		HTTP 方法的幂等性是指一次和多次请求某一个资源应该具有同样的副作用。说白了就是，同一个请求，发送一次和发送 N 次效果是一样的！幂等性是分布式系统设计中十分重要的概念，而 HTTP 的分布式本质也决定了它在 HTTP 中具有重要地位。

1.GET 方法用于获取资源，不应有副作用，所以是幂等的。

1. DELETE 方法用于删除资源，有副作用，但它应该满足幂等性。比如：DELETE http://www.forum.com/article/4231，调用一次和 N 次对系统产生的副作用是相同的，即删掉 id 为 4231 的帖子；因此，调用者可以多次调用或刷新页面而不必担心引起错误。

3.PUT 方法用于创建或更新操作，有副作用，与 DELETE 相同，对同一资源无论调用一次还是多次，其副作用是相同的，因此也满足幂等性。比如：PUT http://www.forum/articles/4231 的语义是创建或更新 ID 为 4231 的帖子。对同一 URI 进行多次 PUT 的副作用和一次 PUT 是相同的；因此，PUT 方法具有幂等性。

4.POST 方法与 PUT 方法的区别主要在于幂等性，POST 不具备幂等性，因为 POST 请求每次都会创建一个文件，而 PUT 方法会在服务器验证是否有 ENTITY，若有则更新该 ENTITY 而不是重新创建。比如：POST http://www.forum.com/articles 的语义是在 http://www.forum.com/articles 下创建一篇帖子，HTTP 响应中应包含帖子的创建状态以及帖子的 URI。两次相同的 POST 请求会在服务器端创建两份资源，它们具有不同的 URI；所以，POST 方法不具备幂等性。

**如何防范 POST 重复提交**

HTTP POST 操作既不是安全的，也不是幂等的（至少在 HTTP 规范里没有保证）。当我们因为反复刷新浏览器导致多次提交表单，多次发出同样的 POST 请求，导致远端服务器重复创建出了资源。

所以，对于电商应用来说，第一、对应的后端 WebService 一定要做到幂等性，第二、服务器端收到 POST 请求，在操作成功后必须 302 跳转到另外一个页面，这样即使用户刷新页面，也不会重复提交表单。

在前端开发中，GET 和 POST 是两种常用的 HTTP 请求方法，它们的主要区别在于数据传输的方式和用途：

1. 数据传输的方式：GET 方法：GET 请求通常用于请求数据，并将请求参数附加到 URL 中。请求的数据会被视为查询字符串，并在 URL 中可见。这意味着 GET 请求的 URL 中包含了所有需要的信息。这也意味着你不能通过 GET 请求发送大量的数据，因为 URL 的长度是有限制的。get比post快两倍。POST 方法：POST 请求通常用于发送数据，并将请求的数据放在请求体中。请求的数据不会在 URL 中可见，可以发送大量的数据。
2. 用途：GET 方法：通常用于获取（或查询）数据，比如获取用户列表、获取某篇文章等。根据 HTTP 规范，GET 请求应该是只读的，并且没有副作用。POST 方法：通常用于发送（或提交）数据，比如创建一个新用户、发布一篇新文章等。POST 请求可能会改变服务器上的数据。
3. 缓存： GET 方法：GET 请求能被浏览器缓存。 POST 方法：POST 请求不会被缓存。
4. 历史记录： GET 方法：GET 请求会被浏览器保存在历史记录中。 POST 方法：POST 请求不会被保存在历史记录中。
5. 书签： GET 方法：可以被添加为书签。POST 方法：不能被添加为书签。
6. 传参：get方法：从服务器获取数据,效率比POST高.GET请求能够被缓存在 HTTP 协议定义中,没有对GET请求的数据大小限制,不过因为浏览器不同一般限制在 2~8K 之间.GET发送请求时,URL中除了资源路径以外,所有的参数(查询字符串)也包装在URL中参数格式在资源路径末尾添加 ? 表示追加参数.每一个变量及值按照 变量名=变量值 方式设定,不能包含空格或者中文.多个参数使用 & 连接.注意 : URL 字符串中如果包含空格或者中文,需要添加百分号转义post方法：

​		向服务器发送数据,也可以获得服务器处理之后的结果,效率不如GET.

​		POST请求不能被缓存.

​		POST提交数据比较大,大小靠服务器的设定值限制,PHP通常限定 2M.

​		POST发送请求时,URL中只有资源路径,但不包含参数,服务器日志不会记录参数,相对更安全.

​		参数被包装成二进制的数据体,格式与 GET 基本一致,只是不包含 ?.

​		注意 : 所有涉及到用户隐私的数据（密码，银行卡号）一定记住使用 POST 方式传递.

​	**7. GET 产生一个 TCP 数据包；POST 产生两个 TCP 数据包。**

- 对于 GET 方式的请求，浏览器会把 http header 和 data 一并发送出去，服务器响应 200（返回数据）；
- 而对于 POST，浏览器先发送 header，服务器响应 100 continue，浏览器再发送 data，服务器响应 200 ok（返回数据）。

```js
axios.get('https://api.example.com/users', {
    params: {
        userId: 123
    }
})
   export let getStats = (a) => { 
       return axios({ 
           url: "/login",
           method: "get", 
           // 传参 
           params: { user: '123123' }
       }); 
axios.post('https://api.example.com/users', {
    name: 'John Doe',
    email: 'john@example.com'
})
.then(function (response) {
    // handle success
    console.log(response.data);
})
.catch(function (error) {
    // handle error
    console.log(error);
})
.finally(function () {
    // always executed
});
```

### 5.2.4 缓存

​		浏览器缓存指在本地使用的计算机中开辟一个内存区，同时也开辟一个硬盘区作为数据传输的缓冲区，然后用这个缓冲区来暂时保存用户以前访问过的信息。

HTTP 缓存主要是通过请求和响应报文头中的对应 Header 信息，来控制缓存的策略。

HTTP缓存可以缩短网页请求资源的距离，减少延迟，节省网络流量，并且由于缓存文件可以重复利用，降低网络负荷，提高客户端响应。缺点是服务端更改内容不能及时同步到客户端。

根据是否需要重新向服务器发起请求，可分为**强缓存和协商缓存**

**1 强缓存**

定义：当命中强缓存的时候，客户端不会再请求服务器，直接从缓存中读取内容，并返回HTTP状态码200。

强制缓存，在响应头由 Expires、Cache-Control 和 Pragma控制

```
Expires：值为服务器返回的过期时间，浏览器再次加载资源时，如果在这个过期时间内，则命中强缓存。（HTTP1.0的属性，缺点是客户端和服务器时间不一致会导致命中误差）(绝对时间)
Cache-Control：HTTP1.1属性，优先级更高，以下为常用属性
	no-store： 禁用缓存
	no-cache：不使用强缓存，每次需向服务器验证缓存是否失效
	private/public：private指的单个用户，public可以被任何中间人、CDN等缓存
	max-age=：max-age是距离请求发起的时间的秒数(相对时间)
	must-revalidate：在缓存过期前可以使用，过期后必须向服务器验证
Pragma
	no-cache：效果和cache-control等no-cache一致。
	优先级Pragma > Cache-Control > Expires
```

**知道 from disk cache和from memory cache吗，他们都是什么时候会触发？**当强缓存的时候会触发这个， 浏览器缓存是存储在磁盘和内存中，当需要使用到缓存的时候会先从内存查找，没有查找到就从磁盘中查找。如果还是找不到就向服务器请求，得到数据再存到内存和磁盘。

**如何刷新强缓存**从上面的强缓存知识中，知道如果缓存时间没有过，我们一直都是在缓存中拿数据的，那么当我们把服务器的数据更新，如何让强缓存也能拿到最新的数据。因为强缓存都是判断url来判断是从缓存中拿数据还是从服务器拿数据，所以只要我们更改了这个url就可以。例如我们在url的后面添加一个version版本或者使用hash来让原来的url改变就可以刷新浏览器的缓存了。

**2 协商缓存**

定义：向服务器发送请求，服务器会根据这个请求的请求头的一些参数来判断是否命中协商缓存，如果命中，则返回304状态码并带上新的响应头通知浏览器从缓存中读取资源。

协商缓存，响应头中有两个字段标记规则

```
Last-Modified / If-Modified-Since
	Last-Modified是浏览器第一个请求资源，服务器响应头字段，是资源文件最后一次更改时间(精确到秒)。
	下一次发送请求时，请求头里的If-Modified-Since就是之前的Last-Modified
	 把浏览器端缓存页面的最后修改时间发送到服务器去，服务器会把这个时间与服务器上实际文件的最后修改时间进行对比。如果时间一致，那么返回304且不返回资源、不返回last-modify，客户端就直接使用本地缓存文件。如果时间不一致，就会返回200和新的文件内容。客户端接到之后，会丢弃旧文件，把新文件缓存起来，并显示在浏览器中.

Etag / If-None-Match：Etag 的校验优先级高于 Last-Modified
	Etag是加载资源时，服务器返回的响应头字段，是对资源的唯一标记，值是hash码， 根据实体内容生成的一段hash字符串（类似于MD5或者SHA1之后的结果），可以标识资源的状态。 当资源发送改变时，ETag也随之发生变化。
	浏览器在下一次加载资源向服务器发送请求时，会将上一次返回的Etag值放到请求头里的If-None-Match里
	服务器接受到If-None-Match的值后，会拿来跟该资源文件的Etag值做比较，如果相同，则表示资源文件没有发生改变，命中协商缓存。
```

**缓存验证流程**

1 ) 浏览器创建了一个请求, 首先请求到达的地方是在本地缓存, 当然是建立在有Cache-Control头的情况下如果在本地缓存里查找，如果找到，则直接返回给浏览器渲染页面这种情况下, 不会经过任何网络的传输，也就是from memory cache的效果2 ) 如果没有找到，就会去网络请求，在网络请求中，如果经过代理服务器(代理缓存)那么首先会在代理服务器上查找相关缓存信息, 如果找到就会返回给客户端经过本地缓存，再返回给浏览器渲染页面3 ) 如果在代理服务器上没有找到该缓存信息，那么就直接去源服务器上查找资源获取了新的内容之后，再逐级向下进行返回和二次缓存最终返回给浏览器进行页面的渲染

**为什么还要使用ETag呢？** 主要是为了解决Last-Modified 无法解决的一些问题：

- 某些服务器不能精确得到文件的最后修改时间， 这样就无法通过最后修改时间来判断文件是否更新了。
- 某些文件的修改非常频繁，在秒以下的时间内进行修改. Last-Modified只能精确到秒。
- 一些文件的最后修改时间改变了，但是内容并未改变。 我们不希望客户端认为这个文件修改了。

https://blog.csdn.net/Tyro_java/article/details/122952039

**协商缓存失效怎么办？**

1. **服务端配置问题**：确保服务端正确地设置了Etag或者Last-Modified响应头，且在收到含有If-None-Match或If-Modified-Since请求头的请求时，能正确地返回304状态码。
2. **网络问题**：一些网络设备或软件可能会修改或移除这些头部信息，导致协商缓存失效。在这种情况下，你可能需要联系你的网络服务提供商或检查你的网络设备和软件配置。
3. **浏览器问题**：不同的浏览器可能在处理协商缓存时有不同的行为。确保你的代码和配置在你的目标浏览器上可以正常工作。

如果协商缓存无法正常工作，你可以采取以下步骤进行调试：

1. **查看网络请求**：在浏览器的开发者工具中查看网络请求，检查请求和响应头部是否正确。查看服务器是否在响应中发送了Etag或Last-Modified，以及是否正确处理了If-None-Match或If-Modified-Since请求头。
2. **查看服务器日志**：服务器的日志可能包含关于请求和响应的有用信息。如果服务器支持，你也可以在服务器上开启详细的日志记录。
3. **检查服务器配置**：确保你的服务器配置正确，并且支持协商缓存。你可能需要查阅你的服务器文档，或者联系你的服务器供应商。

如果问题仍然无法解决，你可能需要寻求专业的帮助，或者考虑使用一种不同的缓存策略。

**3 启发式缓存**

​		只有在没有明确缓存策略时，会激活启发式缓存。所以要合理设置缓存，否则会因没有设置缓存时间等原因，导致内容缓存不刷新。



**接口数据缓存在浏览器**

缓存数据的场景分为两种：

- 与用户无关的数据
- 与用户相关的数据

需要使用缓存的接口是无参数且为get类型的请求

1. 对于用户无关的数据，可以存储在localStorage中
2. 对于用户相关的数据，可以存储在sessionStorage中
3. 不修改原有的接口使用方法，创建一个新的接口调用函数，并使调用方式保持不变
4. 调用该方法时，先创建用于保存的key，再在对应的storage中查找是否有该key的缓存值，有则返回一个伪造的axios请求的Promise结果对象
5. 没有缓存时请求到数据后需要将响应数据保存在本地存储中，并且需注意的是要对请求结果做判断，只保存成功拿到数据的结果，否则一次失败后将无法再获取成功的结果
6. 创建用于缓存数据到localStorage的key时，使用了LOCALSTORAGE_CACHE_VERSION常量，该常用是使用webpack.DefinePlugin插件注入的值，这样是为了让每次重新发版后可以自动刷新本地缓存的数据
7. 创建sessionRequest方法来请求用户相关的数据，与localRequest的区别在于key的创建
8. 关于session缓存用户相关的数据，如果没有userId可供使用，可以使用一个全局的key来代替，确保该key会随着页面的刷新而变化即可，比如可以用进入页面后的某个时间点的时间戳
9. 清除旧的localStorage缓存，由于浏览器对localStorage的大小是有限制的，所以在发版后对于先前保存的数据应当予以清除

参考：

- 接口数据缓存在浏览器 https://juejin.cn/post/7086056735588220958
- https://juejin.cn/post/7074924039348699167

### 5.2.5 tcp|udp

HTTP、TCP 和 UDP 是网络通信中的三个重要协议，它们各自在网络通信的不同层次和环节起到了关键的作用。

HTTP（HyperText Transfer Protocol）是应用层协议，主要用于在Web上传输信息，如HTML文档。它可以运行在TCP之上，也可以运行在其他的网络协议上。HTTP定义了客户端（通常是Web浏览器）如何向服务器发送请求，以及服务器如何返回响应。

TCP（Transmission Control Protocol）是传输层协议，负责在网络中的两个主机之间提供可靠的、有序的和基于字节流的数据传输。TCP使用确认和重传机制来保证数据的可靠传输，并使用拥塞控制机制来避免网络拥塞。HTTP就是运行在TCP之上的一个应用层协议。

UDP（User Datagram Protocol）也是传输层协议，但它与TCP不同，它提供的是一种无连接的服务，数据的传输既不保证可靠，也不保证有序。由于UDP没有TCP那样的确认和重传机制，因此它的开销比TCP小，实时性更好，适合于对实时性要求高的应用，如VoIP（网络电话）和实时视频会议等。

以下是它们的主要区别：

- 可靠性：TCP提供了可靠的数据传输，保证了数据的有序和无误。而UDP不保证数据的可靠传输，数据可能会丢失或者乱序。HTTP运行在TCP之上，因此也是可靠的。
- 连接性：TCP是连接导向的，通信双方在传输数据之前需要先建立连接。而UDP是无连接的，每个数据报都是独立传输的。HTTP作为应用层协议，其连接性取决于底层的传输协议，通常情况下，HTTP会在TCP的基础上建立连接。
- 实时性：由于UDP没有TCP那样复杂的确认和重传机制，因此UDP的实时性更好，适合于对实时性要求高的应用。而HTTP和TCP则更适合于对可靠性要求高的应用。
- 头部开销：TCP的头部开销比UDP大，因为TCP需要包含更多的信息，如序列号、确认号等，以支持它的可靠性和连接性。HTTP的头部开销则取决于HTTP的版本，HTTP/1.1的头部开销比较大，而HTTP/2和HTTP/3采用了头部压缩技术，大大减小了头部开销。
- 使用场景：HTTP主要用于Web应用，如网页浏览、表单提交等。TCP则可以用于各种需要可靠传输的网络应用，如文件传输、电子邮件、远程登录等。UDP则适合于需要快速传输和对实时性要求高的应用，如网络电话、实时视频会议和在线游戏等。

**TCP和 UDP 区别**

TCP 是**面向连接**的、**可靠**的流协议。流就是指不间断的数据结构，当应用程序采用 TCP 发送消息时，虽然可以保证发送的顺序，但还是犹如没有任何间隔的数据流发送给接收端。TCP是面向**面向字节流**，虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序看成是一连串的无结构的字节流。TCP有一个缓冲，当应用程序传送的数据块太长，TCP就可以把它划分短一些再传送。

TCP 为提供可靠性传输，实行“**顺序控制**”或“**重发控制**”机制。此外还具备“**流控制（流量控制）**”、“**拥塞控制**”、提高网络利用率等众多功能。

TCP有以下特点：

- TCP充分地实现了数据传输时各种控制功能，可以进行丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。而这些在 UDP 中都没有。
- 此外，TCP 作为一种面向有连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费。
- 根据 TCP 的这些机制，在 IP 这种无连接的网络上也能够实现高可靠性的通信（ **主要通过检验和、序列号、确认应答、重发控制、连接管理以及窗口控制**等机制实现）。

基于 TCP 的应用层协议：FTP（文件传输）、HTTP（万维网）、SMTP（电子邮件）

当**网络拥塞**时，减少数据的发送。发送方有拥塞窗口，发送数据前比对接收方发过来的接收窗口，取两者的最小值---慢启动、拥塞避免、拥塞发送、快速恢复

**UDP**

​		UDP是一个非连接的协议，传输数据之前源端和终端不建立连接， 当它想传送时就简单地去抓取来自应用程序的数据，并尽可能快地把它扔到网络上。 在发送端，UDP传送数据的速度仅仅是受应用程序生成数据的速度、 计算机的能力和传输带宽的限制； 在接收端，UDP把每个消息段放在队列中，应用程序每次从队列中读一个消息段。

UDP 是**面向报文**的，所谓面向报文，是指面向报文的传输方式是应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。因此，应用程序必须选择合适大小的报文。若报文太长，则IP层需要分片，降低效率。若太短，会是IP太小。

UDP 是**不具有可靠性**的数据报协议，细微的处理它会交给上层的应用去完成。在 UDP 的情况下，虽然可以确保发送消息的大小，却不能保证消息一定会到达。因此，应用有时会根据自己的需要进行重发处理。

UDP有以下特点：

- UDP 不提供复杂的控制机制，利用 IP 提供面向无连接的通信服务。
- 传输途中出现丢包，UDP 也不负责重发。
- 当包的到达顺序出现乱序时，UDP没有纠正的功能。
- 并且它是将应用程序发来的数据在收到的那一刻，立即按照原样发送到网络上的一种机制。即使是出现网络拥堵的情况，UDP 也无法进行流量控制等避免网络拥塞行为。
- 如果需要以上的细节控制，不得不交由采用 UDP 的应用程序去处理。

基于 UDP 的应用层协议：DNS（域名转换）、TFTP（文件传输）、NFS（远程文件服务器）

**UDP**

```js
//UDP收包率低/丢包率高的原因分析
1 缓存太小，不能及时接收数据。
连续多个UDP包超过了UDP接收缓冲区大小 ，比如：
如：UDP包过大 || UDP发包速率过快，突发大数据流量超过了缓冲区上限
2 recvfrom()接收到数据之后处理速度太慢
如果数据接收和处理是连续进行的，那么可能由于数据处理过慢，两次recvfrom调用的时间间隔里发过来的包丢失。

//对应的解决方法
1 UDP包过大
解决方法：增加系统发送或接收缓冲区大小
2 发包速率过快
解决方法:增加应答机制，处理完一个包后，在继续发包
3 recvfrom()接收到数据之后处理速度太慢
服务器程序启动之出，开辟两个线程，一个线程专门用于接收数据包，并存放在应用层的缓存区；另外一个线程用于专门处理和响应数据包请求，避免因为处理数据造成数据丢包。其本质上还是增大了缓冲区大小，只是将系统缓冲区转移到了应用层自己的缓冲区。
4 最复杂的方式
在应用层实现丢包重发机制和超时机制，确保数据包不丢失。

//如果UDP编程的时候的数据大于64kb 会怎么样？
1、在应用层进行数据包的拆分和组合。
2、 大于64KB 时不处理，会交给TCP/IP协议去处理，在网络层进行分包和组包，但是这种方式不用，容易丢包，一旦丢包便整体舍弃，及其不稳定。

//基于UDP实现的协议
DNS（域名解析服务）
```

## 5.3 TCP三次握手与四次挥手

- 第一次握手： 客户端发送syn包(syn=x)到服务器，并进入SYN_SEND状态，等待服务器确认；
- 第二次握手： 服务器收到syn包，必须确认客户的SYN（ack=x+1），同时自己也发送一个SYN包（syn=y），即SYN+ACK包，此时服务器进入SYN_RECV状态；
- 第三次握手： 客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=y+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。
- 握手过程中传送的包里不包含数据，三次握手完毕后，客户端与服务器才正式开始传送数据。理想状态下，TCP连接一旦建立，在通信双方中的任何一方主动关闭连接之前，TCP 连接都将被一直保持下去。

​		与建立连接的“三次握手”类似，断开一个TCP连接则需要“四次握手”。

- 第一次挥手： 主动关闭方发送一个FIN，用来关闭主动方到被动关闭方的数据传送，也就是主动关闭方告诉被动关闭方：我已经不 会再给你发数据了(当然，在fin包之前发送出去的数据，如果没有收到对应的ack确认报文，主动关闭方依然会重发这些数据)，但是，此时主动关闭方还可 以接受数据。
- 第二次挥手： 被动关闭方收到FIN包后，发送一个ACK给对方，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号）。
- 第三次挥手： 被动关闭方发送一个FIN，用来关闭被动关闭方到主动关闭方的数据传送，也就是告诉主动关闭方，我的数据也发送完了，不会再给你发数据了。
- 第四次挥手： 主动关闭方收到FIN后，发送一个ACK给被动关闭方，确认序号为收到序号+1，至此，完成四次挥手。

为什么需要四次挥手?其实是客户端和服务端的两次挥手，也就是客户端和服务端分别释放连接的过程.

​		关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。服务器收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。

- 面试题24：三次握手和四次挥手（计算机网络）  https://blog.csdn.net/qq_51066068/article/details/124439302

## 5.4 Cookie

**cookie 和 token 都存放在 header 中，为什么不会劫持 token？**

​		cookie:登录后服务端生成的sessionid，并在http请求里返回到客户端，同时服务端保存sessionid，以后客户端的每次http请求都带上cookie（sessionid）,服务端会获取cookie（sessionid）然后验证用户的身份。所以拿到cookie就拿到了sessionid，就可验证通过。同时浏览器会自动携带cookie;

​		token：同样是登录后服务端返回一个token，客户端保存起来，在以后http请求里手动的加入到请求头里，服务端根据token 进行身份的校验。浏览器不会自动携带token。

​		token不是为了防止xss攻击的，以CSRF攻击为例：

​		cookie：用户点击了链接，cookie未失效，导致发起请求后后端以为是用户正常操作，于是进行扣款操作；		token：用户点击链接，由于浏览器不会自动带上token，所以即使发了请求，后端的token验证不会通过，所以不会进行扣款操作；

**相同域名不同端口的两个应用，cookie名字、路径都相同的情况下，后面的cookie会覆盖前面的cookie吗？**

如果浏览器访问的服务是ip或localhost的话,会覆盖；如果浏览器访问的是域名(在HOST中配置)的话,不会。

**Cookie的其他的重要作用：**

1. 会话管理：Cookies常常用于记录用户的登录状态。当用户登录一个网站后，服务器会返回一个包含用户ID的cookie，然后浏览器在后续的请求中将这个cookie包含在内，以便服务器知道用户的登录状态。
2. 个性化设置：许多网站允许用户个性化他们的体验，例如更改布局、设置主题、设置语言等。这些设置可以被存储在cookie中，然后在用户下次访问时使用。
3. 跟踪用户行为：Cookies可用于跟踪用户在网站上的行为。例如，网站可以记录用户访问过哪些页面，点击过哪些链接，以便了解用户的兴趣和行为习惯，然后提供个性化的内容或者广告。
4. 状态保持：在没有Cookie的情况下，HTTP协议本身是无状态的，也就是说服务器无法区分两个连续的请求是否来自同一用户。通过使用Cookie，服务器可以在用户的每次请求中识别出用户，以保持用户的状态。

**为什么有些cookie客户端访问不到但是服务端可以？**因为设置了HttpOnly后不能被doc.cookie访问。

1.1）Cookie是什么

- cookie本身是由服务器产生的，生成之后发送给浏览器，并保存在浏览器。
- cookie就是浏览器存储本地目录的一小段文本。
- cookie是以key-value形式存储的。
- cookie大小有限制，为了保证cookie不占用太多磁盘空间，每个cookie大小一般不超过4KB。
- cookie默认在会话结束后直接销毁，此种cookie称之为会话cookie。
- cookie可以设置过期时间，此种cookie称之为持久cookie。
- **相同浏览器下，并且是同源窗口（协议、域名、端口一致），不同页面可以共享localStorage，Cookies值，通过跳转的页面可以共享sessionStorage值。**

Cookie 是服务器发送到用户浏览器并保存在浏览器上的一种数据。它用于在浏览器和服务器间保持状态，例如用户登录信息。以下是一个 Cookie 的主要字段及其作用：

1. Name：Cookie 的名称。每个 Cookie 必须有一个唯一的名称。
2. Value：Cookie 的值。这是存储在 Cookie 中的实际数据。
3. Expires/Max-Age：Cookie 的过期时间。如果设置了 Expires 或 Max-Age，那么在指定的日期或时间后，Cookie 将失效并被浏览器删除。如果没有设置，那么 Cookie 将在浏览器关闭时删除（也就是会话Cookie）。
4. Domain：Cookie 适用的域名。如果没有指定，那么默认为创建 Cookie 的域名。
5. Path：Cookie 适用的路径。它的默认路径是创建 Cookie 的页面的路径。
6. Secure：这个字段没有值。如果指定了 Secure，那么 Cookie 只会在使用 HTTPS 的请求中被发送。
7. HttpOnly：如果cookie中设置了HttpOnly属性，那么通过js脚本将无法读取到cookie信息，这样能有效的防止XSS攻击，窃取cookie内容，这样就增加了cookie的安全性，即便是这样，也不要将重要信息存入cookie。XSS全称Cross SiteScript，跨站脚本攻击，是Web程序中常见的漏洞，XSS属于被动式且用于客户端的攻击方式，所以容易被忽略其危害性。其原理是攻击者向有XSS漏洞的网站中输入(传入)恶意的HTML代码，当其它用户浏览该网站时，这段HTML代码会自动执行，从而达到攻击的目的。如，盗取用户Cookie、破坏页面结构、重定向到其它网站等。
8. SameSite：SameSite属性可以让 Cookie 在跨站请求时不会被发送，从而阻止了跨站请求伪造攻击（CSRF）它有三个可能的值：Strict：Cookie 只会在同站请求中被发送。Lax：在跨站点的导航请求（例如从其他网站的链接到你的网站）时，Cookie 也会被发送。None：无论是否跨站，都会发送 Cookie。如果设置 SameSite=None，那么必须同时设置 Secure。

1.2）Cookie的不足

- 每个cookie容量有限，大小一般不超过4KB。
- 因为cookie由浏览器存储在本地目录，所以不方便记录敏感信息，如密码等。
- cookie不支持跨域访问。
- cookie不支持手机端方案。

2.1) Session是什么

- session是由服务器产生的，存储在服务端等（使用 session 需要把 cookie 设为 HttpOnly）。
- session的存储形式多种多样，可以是文件、数据库、缓存等，这需要靠程序如何设计。
- session也是以key-value形式存储的。
- session是没有大小限制的，这比cookie灵活很多，不过将过多的东西放在其中也并不是明智的做法。
- session也有过期时间的概念，默认为30分钟，可以通过tomcat、web.xml等方式进行配置。
- session可以主动通过invalidate()方法进行销毁。
- session通过session_id识别，如果请求持有正确的session_id，则服务器认为此请求处于session_id代表的会话中。

2.2）Session的不足

- session大小不限制，存储在服务端，本身是对资源的一种负担。
- 如何保证session的高可用、准确性，优势对整体架构的一种负担。
- 频繁的创建、查询、验证session，会对服务器造成很大的压力。
- session是有状态的。

3.1）Token是什么

- token是一种轻量级的用户验证方式。
- token是无状态的。
- token允许跨域访问。
- token是服务端生成的一个字符串，保存在客户端（一般放在localStorage中，也可以放在cookie中），作为请求服务的验证令牌。
- token无需存放在服务端，这样服务端无需存放用户信息。
- token对服务端压力极小`，因为服务端只需存储秘钥，并支持生成token的算法，无需存储token。
- token最简单的构造：用户唯一的身份标识(辨识用户) + 时间戳(用于过期校验) + 签名(防止第三方恶意冒充)。
- token无法主动过期，只能等待它达到过期时间后才会失效。
- token的产生：首次请求时，服务器对请求参数（如账号、密码）验证通过，则根据用户标识，加上服务的密钥，通过生成算法，生成token。
- token的验证：再次请求时，携带此token，则服务端再次根据用户标识，生成token，根据两个token是否一致且未过期来判定用户是否已授权。

3.2）token的不足

- token无法主动过期，只能等待它达到过期时间后才会失效。
- token本身比session_id要大，会消耗更多的流量与贷款。

3.4）Token的组成

​		token 其实就是一串字符串而已，只不过它是被加密后的字符串，它通常使用 uid(用户唯一标识)、时间戳、签名以及一些其它参数加密而成。我们将 token 进行解密就可以拿到诸如 uid 这类的信息，然后通过 uid 来进行接下来的鉴权操作。**被存放在****`config.headers.Authorization`**

**关于为什么不把****`token`****放在****`Cookie`****里**，实际上，一些应用确实会将`token`存储在`Cookie`中。然而，这样做有一些风险：

1. **跨站请求伪造（CSRF）**：如果`token`被存储在`Cookie`中，攻击者可能会利用用户在浏览器中的登录状态，伪造请求到服务器。这是因为浏览器在向服务器发送请求时会自动带上`Cookie`，攻击者可以利用这个特性进行攻击。
2. **跨站脚本（XSS）**：`token`在`Cookie`中可能会被恶意脚本访问，如果网站有XSS漏洞，那么这些`Cookie`就可能被盗取。

因此，有些应用选择将`token`存储在`localStorage`或`sessionStorage`中，或者在每次请求时在`HTTP`头部中明确地发送`token`，以减少安全风险。然而，这些方法也有自己的风险，例如，`localStorage`也容易受到XSS攻击。因此，安全性的实现需要根据具体的应用场景和需求来考虑。

**Token放在localStorage安全吗**

Web存储（localStorage/sessionStorage）可以通过同一域商Javascript访问。这意味着任何在你的网站上的运行的JavaScript都可以访问Web存储，所以容易受到XSS攻击。尤其是项目中用到了很多第三方JavaScript类库。

为了防止XSS，一般的处理是避开和编码所有不可信的数据。但这并不能百分百防止XSS。比如我们使用托管在CDN或者其它一些公共的JavaScript库，还有像npm这样的包管理器导入别人的代码到我们的应用程序中。

关于token 存在cookie还是localStorage有两个观点。

- 支持Cookie的开发人员会强烈建议不要将敏感信息（例如JWT)存储在localStorage中，因为它对于XSS毫无抵抗力。
- 支持localStorage的一派则认为：撇开localStorage的各种优点不谈，如果做好适当的XSS防护，收益是远大于风险的。

**4）浏览器关闭**

​		session保存在服务器端，会一直存在，默认存在时间30分钟；cookie保存sessionid，服务器会根据cookie中sessionid获取session；

两种类型的Cookie：

- 临时Cookie（会话Cookie）
- 永久Cookie

​		不设置过期时间，则表示这个cookie生命周期为浏览器会话期间，只要关闭浏览器窗口，cookie就消失了。这种生命期为浏览会话期的cookie被称为会话cookie。会话cookie一般不保存在硬盘上而是保存在内存里。

​		设置了过期时间，浏览器就会把cookie保存到硬盘上，关闭后再次打开浏览器，这些cookie依然有效直到超过设定的过期时间。

​		存储在硬盘上的cookie可以在不同的浏览器进程间共享，比如两个IE窗口。而对于保存在内存的cookie，不同的浏览器有不同的处理方式。

​		为何关闭浏览器后，再次访问会觉得session失效了呢，这里的失效意思是session的数据丢失了？

​		其实这里session数据并没有丢失，只是关闭浏览器后，因为默认的cookie生命周期为浏览器的缓存，即关掉浏览器之后cookie就失效了，此时sessionid也就没有了。再次访问后，服务器又生成一个新的sessionid，此时request.getSession()通过sessionid获取到的session就不是之前的session了。		系统在关闭之后再次打开，如果此时的token没有过期的话，用户无需登录就可以进入主页。

5）总结

| Cookie  | 1.存储在客户端。2.请求自动携带 cookie。3.存储大小 4KB。 | 1.兼容性好，因为是比较老的技术。2.很容易实现，因为 cookie 会自动携带和存储。 | 1.需要单独解决跨域携带问题，比如多台服务器如何共享 cookie。2.会遭受 CSRF 攻击。3.存储在客户端，不够安全。 |
| ------- | ------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Session | 1.存储在服务端。2.存储大小无限制。                      | 1.查询速度快，因为是个会话，相当于是在内存中操作。2.结合 cookie 后很容易实现鉴权。3.安全，因为存储在服务端。 | 1.耗费服务器资源，因为每个客户端都会创建 session。2.占据存储空间，session 相当于存储了一个完整的用户信息。 |
| Token   | 1.体积很小。2.自由操作存储在哪里。                      | 1.安全，因为 token 一般只有用户 id，就算被截取了也没什么用。2.无需消耗服务器内存资源，它相当于只存了用户 id，session 相当于存储了用户的所有信息。3.跨域处理较为方便，比如多台服务器之间可以共用一个 token。 | 1.查询速度慢，因为 token 只存了用户 id，每次需要去查询数据库。 |

## 5.5 OSI七层模型

**1 物理层：**

​		实现计算机节点之间比特流的透明传送。

**2 数据链路层：**

​		数据链路层通常也叫做链路层，在物理层和网络层之间。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层协议。

​		在两个相邻节点之间传送数据时，数据链路层将网络层交下来的 IP数据报组装成帧，在两个相邻节点间的链路上传送帧每一帧的数据可以分成：报头head和数据data两部分:head 标明数据发送者、接受者、数据类型，如 MAC地址。data 存储了计算机之间交互的数据。

**3 网络层（IP）：**

​		网络层的主要任务就是选择合适的网间路由和交换节点，确保数据按时成功传送。

**4 传输层（TCP/UDP）：**

​		传输层的主要任务是为两台主机进程之间的通信提供服务，处理数据包错误、数据包次序，以及其他一些关键传输问题。协议：TCP控制传输协议，UDP用户数据报协议，SCTP流控制传输协议，PPTP点对点隧道协议。

**5 会话层：**

​		会话层就是负责建立、管理和终止表示层实体之间的通信会话。

**6 表示层：**

​		表示层的作用是使通信的应用程序能够解释交换数据的含义，该层提供的服务主要包括数据压缩，数据加密以及数据描述，使应用程序不必担心在各台计算机中表示和存储的内部格式差异。

**7 应用层（http）：**

​		该层协议定义了应用进程之间的交互规则，通过不同的应用层协议为不同的网络应用提供服务。例如域名系统 DNS，支持万维网应用的 HTTP 协议，电子邮件系统采用的 SMTP协议等

## 5.6 Http状态码

状态码第一位数字决定了不同的响应状态，有如下：**设置在响应头的location中**。

1 表示消息2 表示成功3 表示重定向4 表示请求错误5 表示服务器错误

- 101 Switching Protocol（协议切换）状态码表示服务器应客户端升级协议的请求对协议进行切换。
- 200（成功）：请求已成功，请求所希望的响应头或数据体将随此响应返回
- 206：在客户端表明只需要URL上的部分资源的时候返回的.这种情况经常发生在客户端继续请求一个未完成的下载的时候(通常是当客户端加载一个体积较大的嵌入文件,比如视屏或PDF文件),或者是客户端尝试实现带宽遏流的时候.
- 204 服务器成功处理了请求，但是没有返回任何内容。
- 301：永久重定向会缓存。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替。新域名替换旧域名，旧的域名不再使用时，用户访问旧域名时用301就重定向到新的域名(两者都是一个POST请求经过 301/302 后会被浏览器转为GET请求)
- 302：重定向是临时的，客户端应当继续向原有地址发送以后的请求。请求的资源现在临时从不同的 URI 响应请求。只有在Cache-Control或Expires中进行了指定的情况下，这个响应才是可缓存的。
- 303：与301类似。使用GET和POST请求查看
- 304：未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源。**命中协商缓存**
- 305：使用代理。所请求的资源必须通过代理访问
- 400（错误请求）： 服务器不理解请求的语法
- 401（未授权）： 请求要求身份验证。 对于需要登录的网页，服务器可能返回此响应。
- 403：服务器理解请求客户端的请求，但是拒绝执行此请求
- 404（未找到）： 服务器找不到请求的网页
- 405（方法禁用）： 禁用请求中指定的方法，CORS没有配置跨域时。
- 422:请求格式正确，但是由于含有语义错误，无法响应。
- 500 —— 服务器内部异常
- 501： 服务器不支持请求的功能，无法完成请求
- 503：服务器停机维护时，主动用503响应请求或 nginx 设置限速，超过限速，会返回503
- 504：充当网关或代理的服务器，未及时从远端服务器获取请求
- 505：服务器不支持请求的HTTP协议的版本，无法完成处理

## 5.7 CDN

​		CDN(全称 Content Delivery Network)，即内容分发网络构建在现有网络基础之上的智能虚拟网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。`CDN` 的关键技术主要有内容存储和分发技术。

​		简单来讲，`CDN`就是根据用户位置分配最近的资源。于是，用户在上网的时候不用直接访问源站，而是访问离他“最近的”一个 CDN 节点，术语叫**边缘节点**，其实就是缓存了源站内容的代理服务器。

​		1 在没有应用CDN时，我们使用域名访问某一个站点时的路径为：

​		用户提交域名→浏览器对域名进行解释→DNS 解析得到目的主机的IP地址→根据IP地址访问发出请求→得到请求数据并回复

​		2 应用CDN后，DNS 返回的不再是 IP 地址，而是一个CNAME(Canonical Name ) 别名记录，指向CDN的全局负载均衡

​		CNAME实际上在域名解析的过程中承担了中间人（或者说代理）的角色，这是CDN实现的关键

​		**CDN加速的本质是缓存加速**。将服务器上存储的静态内容缓存在CDN节点上，当访问这些静态内容时，无需访问服务器源站，就近访问CDN节点即可获取相同内容，从而达到加速的效果，同时减轻服务器源站的压力。「    前端可以缓存部分文件，js、css等等，但是像图片、视频这些大文件缓存就比较难，而且如果是初次加载，前端缓存效率也是比较低的，得先加载服务器资源，再缓存到服务器，CDN初次加载效率会高一些。静态资源指的是在不同请求中访问到的数据都相同的静态文件。例如：图片、视频、网站中的文件（html、css、js）、软件安装包、apk文件、压缩包文件等。」

**缓存代理**

缓存系统是 `CDN`的另一个关键组成部分，缓存系统会有选择地缓存那些最常用的那些资源

其中有两个衡量`CDN`服务质量的指标：

- 命中率：用户访问的资源恰好在缓存系统里，可以直接返回给用户，命中次数与所有访问次数之比
- 回源率：缓存里没有，必须用代理的方式回源站取，回源次数与所有访问次数之比

缓存系统也可以划分出层次，分成一级缓存节点和二级缓存节点。一级缓存配置高一些，直连源站，二级缓存配置低一些，直连用户

回源的时候二级缓存只找一级缓存，一级缓存没有才回源站，可以有效地减少真正的回源





## 5.9 JWT

​		JWT（JSON web token）是一个JSON信息传输的开放标准，它可以使用密钥对信息进行数字签名(生成token)，以确保信息是可验证和可信任的。JWT由三部分构成：header（头部）、payload（载荷）和signature（签名）。

```
header承载两部分信息：
{'typ': 'JWT',	  //声明类型 这里是jwt
  'alg': 'HS256'} //声明加密的算法 通常直接使用 HMAC SHA256
payload存放有效信息的地方。这个名字像是特指飞机上承载的货品，这些有效信息包含三个部分：标准中注册的声明、公共的声明、私有的声明
signature是一个签证信息，这个签证信息由三部分组成：header (base64后的)、payload (base64后的)和secret
	
```

**注意**：**secret是保存在服务器端的，jwt的签发生成也是在服务器端的**，secret就是用来进行jwt的签发和jwt的验证，所以，它就是你服务端的私钥，在任何场景都不应该流露出去。一旦客户端得知这个secret, 那就意味着客户端是可以自我签发jwt了。

**基于Session的认证：**

1. 首先用户向服务器发送用户名和密码。
2. 然后服务器将数据保存再，session里面。
3. 服务器向用户返回一个session_id，写入给用户的Cookie。
4. 用户之后的每一次请求，都会将通过Cookie将session_id返回到服务器。
5. 服务器收到了session_id，找到前期保存的数据，从而得到用户的身份。

基于session认证所显露的问题：

1. Session: 每个用户经过我们的应用认证之后，我们的应用都要在服务端做一次记录，以方便用户下次请求的鉴别，通常而言session都是保存在内存中，而随着认证用户的增多，服务端的开销会明显增大。
2. 扩展性: 用户认证之后，服务端做认证记录，如果认证的记录被保存在内存中的话，这意味着用户下次请求还必须要请求在这台服务器上,这样才能拿到授权的资源，这样在分布式的应用上，相应的限制了负载均衡器的能力。这也意味着限制了应用的扩展能力。
3. CSRF: 因为是基于cookie来进行用户识别的, cookie如果被截获，用户就会很容易受到跨站请求伪造的攻击。

**基于token的鉴权机制**

基于token的鉴权机制类似于http协议也是无状态的，它不需要在服务端去保留用户的认证信息或者会话信息。这就意味着基于token认证机制的应用不需要去考虑用户在哪一台服务器登录了，这就为应用的扩展提供了便利。

流程上是这样的：

1. 用户使用用户名密码来请求服务器
2. 服务器进行验证用户的信息
3. 服务器通过验证发送给用户一个token
4. 客户端存储token，并在每次请求时附送上这个token值
5. 服务端验证token值，并返回数据

这个token必须要在每次请求时传递给服务端，它应该保存在请求头里， 另外，服务端要支持**CORS(跨来源资源共享)策略**，一般我们在服务端这么做`Access-Control-Allow-Origin: *`。

**JWT优点**

1. 因为json的通用性，所以JWT是可以进行跨语言支持的，像JAVA,JavaScript,NodeJS,PHP等很多语言都可以使用；
2. 因为有了payload部分，所以JWT可以在自身存储一些其他业务逻辑所必要的非敏感信息；
3. 便于传输，jwt的构成非常简单，字节占用很小，所以它是非常便于传输的；
4. 它不需要在服务端保存会话信息, 所以它易于应用的扩展。

**JWT缺点**

1. 不应该在jwt的payload部分存放敏感信息，因为该部分是客户端可解密的部分；
2. 保护好secret私钥，该私钥非常重要；
3. 如果可以，请使用https协议。
4. 一旦生成就无法更改。

## 5.11 网站攻击

**1.CSRF攻击**

​		 跨站请求伪造是一种对网站的恶意利用，也被称为 one-click attack 或者 session riding，通常缩写为 CSRF 或者 XSRF， 是一种挟制用户在当前已登录的Web应用程序上执行非本意的操作的攻击方法。 CSRF跨站点请求伪造(Cross—Site Request Forgery) 跟XSS攻击一样，存在巨大的危害性。**https 不能防范 csrf 攻击。**

```
攻击者盗用了你的身份，以你的名义发送恶意请求，对服务器来说这个请求是完全合法的，但是却完成了攻击者所期望的一个操作，比如以你的名义发送邮件、发消息，盗取你的账号，添加系统管理员，甚至于购买商品、虚拟货币转账
```

1. 用户C打开浏览器，访问受信任网站A，输入用户名和密码请求登录网站A；
2. 在用户信息通过验证后，网站A产生Cookie信息并返回给浏览器，此时用户登录网站A成功，可以正常发送请求到网站A；
3. 用户未退出网站A之前，在同一浏览器中，打开一个TAB页访问网站B；
4. 网站B接收到用户请求后，返回一些攻击性代码，并发出一个请求要求访问第三方站点A；
5. 浏览器在接收到这些攻击性代码后，根据网站B的请求，在用户不知情的情况下携带Cookie信息，向网站A发出请求。网站A并不知道该请求其实是由B发起的，所以会根据用户C的Cookie信息以C的权限处理该请求，导致来自网站B的恶意代码被执行。

两个条件：

1. C 用户访问站点 A 并产生了 cookie
2. C 用户没有退出 A 同时访问了 B

防御：

1. 利用Http 的 Refer 字段

​		根据 HTTP 协议，在 HTTP 头中有一个字段叫 Referer，它记录了该 HTTP 请求的来源地址 。在通常情况下，访问一个安全受限页面的请求来自于同一个网站。因此，要防御 CSRF 攻击，网站只需要对于每一个转账请求验证其 Referer 值，如果是以 bank.example 开头的域名，则说明该请求是来自银行网站自己的请求，是合法的。如果 Referer 是其他网站的话，则有可能是黑客的 CSRF 攻击，拒绝该请求。

1. 在请求地址中添加 token

​		CSRF 攻击之所以能够成功，是因为黑客可以完全伪造用户的请求，该请求中所有的用户验证信息都是存在于 cookie 中，因此黑客可以在不知道这些验证信息的情况下直接利用用户自己的 cookie 来通过安全验证。要抵御 CSRF，关键在于 在请求中放入黑客所不能伪造的信息，并且该信息不存在于 cookie 之中 。可以在 HTTP 请求中以参数的形式加入一个随机产生的 token，并在服务器端建立一个拦截器来验证这个 token，如果请求中没有 token 或者 token 内容不正确，则认为可能是 CSRF 攻击而拒绝该请求。

优点：这种方法要比检查 Referer 要安全一些，token 可以在用户登陆后产生并放于 session 之中 ，然后在每次请求时把 token 从 session 中拿出，与请求中的 token 进行比对，但这种方法的难点在于如何把 token 以参数的形式加入请求。对于 GET 请求，token 将附在请求地址之后，这样 URL 就变成 http://url?csrftoken=tokenvalue。 而对于 POST 请求来说，要在 form 的最后加上 ，这样就把 token 以参数的形式加入请求了。

缺点：

​		但是，在一个网站中，可以接受请求的地方非常多，要对于每一个请求都加上 token 是很麻烦的，并且很容易漏掉，通常使用的方法就是在每次页面加载时，使用 javascript 遍历整个 dom 树，对于 dom 中所有的 a 和 form 标签后加入 token。这样可以解决大部分的请求，但是对于在页面加载之后动态生成的 html 代码，这种方法就没有作用，还需要程序员在编码时手动添加 token。		该方法还有一个缺点是难以保证 token 本身的安全。特别是在一些论坛之类支持用户自己发表内容的网站，黑客可以在上面发布自己个人网站的地址。由于系统也会在这个地址后面加上 token，黑客可以在自己的网站上得到这个 token，并马上就可以发动 CSRF 攻击。为了避免这一点，系统可以在添加 token 的时候增加一个判断，如果这个链接是链到自己本站的，就在后面添加 token，如果是通向外网则不加。不过，即使这个 token 不以参数的形式附加在请求之中，黑客的网站也同样可以通过 Referer 来得到这个 token 值以发动 CSRF 攻击。这也是一些用户喜欢手动关闭浏览器 Referer 功能的原因。

1. 在 http 中自定义属性并验证

​		这种方法也是使用 token 并进行验证，和上一种方法不同的是，这里并不是把 token 以参数的形式置于 HTTP 请求之中，而是把它放到 HTTP 头中自定义的属性里。通过 XMLHttpRequest 这个类，可以一次性给所有该类请求加上 csrftoken 这个 HTTP 头属性，并把 token 值放入其中。这样解决了上种方法在请求中加入 token 的不便，同时，通过 XMLHttpRequest 请求的地址不会被记录到浏览器的地址栏，也不用担心 token 会透过 Referer 泄露到其他网站中去。

缺点：

​		然而这种方法的局限性非常大。XMLHttpRequest 请求通常用于 Ajax 方法中对于页面局部的异步刷新，并非所有的请求都适合用这个类来发起，而且通过该类请求得到的页面不能被浏览器所记录下，从而进行前进，后退，刷新，收藏等操作，给用户带来不便。另外，对于没有进行 CSRF 防护的遗留系统来说，要采用这种方法来进行防护，要把所有请求都改为 XMLHttpRequest 请求，这样几乎是要重写整个网站，这代价无疑是不能接受的。

**2.XSS攻击**

​		跟跨网站脚本(XSS)相比，XSS 利用的是用户对指定网站的信任，CSRF 利用的是网站对用户网页浏览器的信任。

​		XSS攻击是指攻击者通过执行恶意脚本来攻击Web应用程序，从而在受害者的浏览器中执行恶意代码。XSS攻击可以分为三种类型：存储型XSS和反射型XSS。存储型XSS是指攻击者将恶意脚本存储在Web应用程序的数据库中，当用户访问包含恶意脚本的页面时，恶意脚本会被执行。存储型XSS攻击通常发生在留言板，评论区等需要用户输入内容的地方。反射型XSS是指攻击者将恶意脚本作为参数发送给Web应用程序，Web应用程序将恶意脚本反射给用户的浏览器，从而执行恶意代码。反射型XSS攻击通常发生在搜索框，登录框等需要用户输入内容的地方。DOM XSS基于 DOM 的 XSS 攻击是指通过恶意脚本修改页面的 DOM 结构，是纯粹发生在客户端的攻击。DOM 型 XSS 跟前两种 XSS 的区别：**DOM 型 XSS 攻击中，取出和执行恶意代码由浏览器端完成，属于前端 JavaScript 自身的安全漏洞，而其他两种 XSS 都属于服务端的安全漏洞**。

​		作为一种HTML注入攻击，XSS攻击的核心思想就是在HTML页面中注入恶意代码，而XSS采用的注入方式是非常巧妙的。在XSS攻击中，一般有三个角色参与：攻击者、目标服务器、受害者的浏览器。

​		由于有的服务器并没有对用户的输入进行安全方面的验证，攻击者就可以很容易地通过正常的输入手段，夹带进一些恶意的HTML脚本代码。当受害者的浏览器访 问目标服务器上被注入恶意脚本的页面后，由于它对目标服务器的信任，这段恶意脚本的执行不会受到什么阻碍。而此时，攻击者的目的就已经达到了。

下面我们以一段简单的JavaScript脚本为例，来描述整个XSS攻击的过程：

<script>alert(document.cookie);</script>

上面这段脚本的执行具体内容就是弹出一个对话框显示用户的Cookie信息。攻击者在向目标服务器的某个页面进行数据输入的过程中，通过正常的输入方式夹带进这段脚本。

危害：

1.窃取用户Cookie2.后台增删改文章3.XSS钓鱼攻击4.利用XSS漏洞进行传播和修改网页代码5.XSS蠕虫攻击6.网站重定向7.获取键盘记录8.获取用户信息等

防御：

通过前面的介绍可以得知，XSS 攻击有两大要素：

1. 攻击者提交恶意代码。
2. 浏览器执行恶意代码。

根本的解决方法：**从输入到输出都需要过滤、转义。**

1、对输入和URL参数进行过滤(白名单和黑名单)检查用户输入的数据中是否包含一些特殊字符，如<、>、’、“等，发现存在特殊字符，将这些特殊字符过滤或者编码。

2、富文本的事件肯定要被禁止，因为富文本并不需要事件这种东西，另外一些危险的标签也需要禁止，例如：` <iframe>，<script>，<base>，<form>`等

3、所有需要输出到 HTML 页面的变量，全部需要使用编码或者转义来防御

4、安全头，这是浏览器自带的防范能力，一般是通过开启 Web 安全头生效的。**CSP**：W3C 的 Content Security Policy，简称 CSP，主要是用来定义页面可以加载哪些资源，减少 XSS 的发生。**X-XSS-Protection**：IE 提供的一些 XSS 检测与防范，默认开启

5、HTTP-only Cookie。攻击者可以通过注入恶意脚本获取用户的 Cookie 信息。通常 Cookie 中都包含了用户的登录凭证信息，攻击者在获取到 Cookie 之后，则可以发起 Cookie 劫持攻击。所以，严格来说，HttpOnly 并非阻止 XSS 攻击，而是能阻止 XSS 攻击后的 Cookie 劫持攻击。

https://zhuanlan.zhihu.com/p/61773197



**3 中间人攻击（MITM）**

​		中间人攻击本质上是窃听攻击。举个例子，小明用微信发一条消息给小红，这条消息会从小明的手机发送到微信的服务器，再由微信服务器转发给小红，理论上讲，微信服务器是可以查看或者修改小明发送的信息的。这个时候，微信服务器就可以是实施攻击的中间人。

​		攻击流程（Fiddler抓包为例）：

- 黑客通过特殊途径在被攻击者的手机上安装根证书；
- 客户端发起连接请求，代理服务器（Fiddler）在中间截取请求，返回自己签名的伪造证书；
- 客户端收到证书后会在系统中查找信任的根证书，因为黑客已经事先在被攻击者手机上安装了自己的根证书，因此客户端验证通过；
- 客户端后续就会把Fiddler当成合法的服务器；
- 而Fiddler会与真实的服务器通信，截获密钥，解密数据。

​		对https：

​		对于https来说，客户端或者操作系统内置了权威CA(certification authority)的根证书，而服务器在通信之初，会先返回在CA那里获取的签名证书，然后客户端用根证书验证证书有效性，最后使用验证通过的证书提供的公钥加密数据。前提假设是权威的证书机构不会把签名信息泄露出去。

​		早年12306非得使用自己签名的证书，而主流浏览器又不认可，导致用户需要在首次下载证书并安装。这其实是个很危险的操作，不法分子完全可以利用这个机制把非法证书安装到用户设备上。好在现在12306已经采用DigiCert颁布的证书了。

## 5.12 WebSocket

​		WebSocket 是一种在单个TCP连接上进行全双工通信的协议(应用层协议)。WebSocket 使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。		在 WebSocket API 中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接， 并进行双向数据传输。

​		原来WebSocket根本不附属于同源策略，而且它本身就有意被设计成可以跨域的一个手段。由于历史原因，跨域检测一直是由浏览器端来做，但是WebSocket出现以后，对于WebSocket的跨域检测工作就交给了服务端，浏览器仍然会带上一个`Origin`跨域请求头，服务端则根据这个请求头判断此次跨域WebSocket请求是否合法。

**1 连接过程**

首先，客户端发起http请求，经过3次握手后，建立起TCP连接；http请求里存放WebSocket支持的版本号等信息，如：Upgrade、Connection、WebSocket-Version等；

```
Connection: Upgrade`该`Connection`头被设置为`"Upgrade"`以表示的升级要求。`Upgrade:
protocols
```

然后，服务器收到客户端的握手请求后，同样采用HTTP协议回馈数据；

最后，客户端收到连接成功的消息后，开始借助于TCP传输信道进行全双工通信。

```js
var socket = new WebSocket("ws://localhost:8765");

socket.onmessage = function(event) {
    var img = document.createElement('img');
    img.src = 'data:image/png;base64,' + event.data;
    document.body.appendChild(img);
}
```

**2 与http**

相同点： 都是一样基于TCP的，都是可靠性传输协议。都是应用层协议。

联系： WebSocket在建立握手时，数据是通过HTTP传输的。但是建立之后，在真正传输时候是不需要HTTP协议的。

因为 HTTP 协议有一个缺陷：通信只能由客户端发起，不具备服务器推送能力。举例来说，我们想了解查询今天的实时数据，只能是客户端向服务器发出请求，服务器返回查询结果。HTTP 协议做不到服务器主动向客户端推送信息。

如果我们需要通过网络传输的任何实时更新或连续数据流，则可以使用WebSocket。如果我们要获取旧数据，或者只想获取一次数据供应用程序使用，则应该使用HTTP协议，不需要很频繁或仅获取一次的数据可以通过简单的HTTP请求查询，因此在这种情况下最好不要使用WebSocket。

**3 心跳检测**

1. 客户端每隔一个时间间隔发生一个探测包给服务器
2. 客户端发包时启动一个超时定时器
3. 服务器端接收到检测包，应该回应一个包
4. 如果客户机收到服务器的应答包，则说明服务器正常，删除超时定时器
5. 如果客户端的超时定时器超时，依然没有收到应答包，则说明服务器挂了

**4 轮询 长连接**

1.轮询：客户端定时向服务器发送请求，服务器接到请求后马上返回响应信息并关闭连接。

优点：后端程序编写比较容易。

缺点：请求中有大半是无用，浪费带宽和服务器资源。这种方式由于需要不断的建立http连接，严重浪费了服务器端和客户端的资源。

实例：短轮询不适用于那些同时在线用户数量比较大，并且很注重性能的Web应用。适于小型应用。

2.长轮询：客户端向服务器发送请求，服务器接到请求后hold住连接，直到有新消息才返回响应信息并关闭连接（或到了设定的超时时间关闭连接），客户端处理完响应信息后再向服务器发送新的请求。

优点：减少了很多不必要的http请求次数，相比之下节约了资源。

缺点：服务器hold连接会消耗资源，需要同时维护多个线程，服务器所能承载的TCP连接数是有上限的，这种轮询很容易把连接数顶满。

实例：WebQQ、Facebook IM。

3.长连接：HTTP1.1通过使用Connection:keep-alive进行长连接，HTTP 1.1默认进行持久连接。在一次 TCP 连接中可以完成多个 HTTP 请求，但是对每个请求仍然要单独发 header。也就是想要获得数据，就必须先发送一个request才能得到一个response，所以在实时监控、推送、视频直播等实时性较高或者带宽利用较苛刻的场景，仍然不是很合适。

SSE是HTML5新增的功能，全称为Server-Sent Events。它可以允许服务推送数据到客户端。SSE在本质上就与之前的长轮询、短轮询不同，虽然都是基于http协议的，但是轮询需要客户端先发送请求。而SSE最大的特点就是不需要客户端发送请求，可以实现只要服务器端数据有更新，就可以马上发送到客户端。

SSE的优势很明显，它不需要建立或保持大量的客户端发往服务器端的请求，节约了很多资源，提升应用性能。并且后面会介绍道，SSE的实现非常简单，并且不需要依赖其他插件。和websocket相比，只能单工通信，建立连接后，只能由服务端发往客户端，且占用一个连接，如需客户端向服务端通信，需额外打开一个连接

兼容性：短轮询>长轮询>长连接>WebSocket

性能：WebSocket>长连接>长轮询>短轮询

参考：

https://www.ruanyifeng.com/blog/2017/05/websocket.html

https://juejin.cn/post/7020964728386093093

## 5.13 跨域和同源

​		当一个请求url的协议、域名、端口三者之间任意一个与当前页面ur不同即为跨域

​		在当前，前后端分离的开发模式下，跨域问题是经常遇到的，**OPTIONS**只不过CORS机制当中的一个预检测请求。而且这个请求是整个CORS机制控制的，并不能在前端用代码进行控制。主要作用：1.检测服务器支持的请求方法  2.CORS 中的预检请求。（简单请求并不会进行预请求，加token不属于简单请求）

​		如果不想让每个CORS复杂请求都出两次请求，可以设置Access-Control-Max-Age这个属性。让浏览器缓存，在缓存的有效期内，所有options请求都不会发送。优化性能。

**同源策略**：同源策略是浏览器的一种安全策略，用于限制一个源的文档或脚本如何能与另一个源的资源进行交互。目的是防止恶意网站从用户的浏览器中窃取敏感信息或进行恶意攻击；用于保护浏览器用户的数据安全。在这个策略下，web浏览器允许第一个页面的脚本访问第二个页面里的数据，但是也只有在两个页面有相同的源时。源是由`URI，主机名，端口号`组合而成的。这个策略可以阻止一个页面上的恶意脚本通过页面的DOM对象获得访问另一个页面上敏感信息的权限。

- 协议相同
- 域名相同
- 端口相同

同源策略限制内容有：

- Cookie、LocalStorage、IndexedDB 等存储性内容
- DOM节点
- AJAX跨域请求的数据

需要跨域请求的情况通常发生在以下场景：

1. 前后端分离的开发模式：在前后端分离的开发模式中，前端代码和后端代码可能会部署在不同的服务器上，因此前端需要向不同的服务器请求数据，从而需要进行跨域请求。
2. CDN加速：网站可能使用了CDN技术，将资源文件分布在不同的服务器上，从而提高网站的访问速度。但是，由于CDN服务器和原始服务器位于不同的域名下，因此需要进行跨域请求。
3. 第三方服务接口：如果你的网站需要使用第三方服务提供的API接口来获取数据，那么很可能需要进行跨域请求。

**跨域解决方案：**

1. CORS（Cross Origin Resource Share跨域资源共享）CORS是W3C标准，需要服务器端配合实现。 浏览器会自动发送一个预检请求（OPTIONS请求）来检查服务器是否允许跨域访问，如果允许则发送真正的请求。（CORS请求相关的字段，都以Access-Control-开头） 服务器端需要在响应头中设置Access-Control-Allow-Origin等相关字段来告知浏览器允许的跨域访问。要想操作cookie，需要满足3个条件：1） 服务的响应头中需要携带Access-Control-Allow-Credentials并且为true。2）浏览器发起ajax需要指定withCredentials 为true3）响应头中的Access-Control-Allow-Origin一定不能为*，必须是指定的域名如果设置为*的风险：数据安全风险：这个设置允许任何域对你的资源进行跨域请求，这很可能会暴露你的数据给你不想让其接触的第三方。某些恶意站点可能会尝试利用这个漏洞获取敏感信息。无法使用凭证：当你设置 Access-Control-Allow-Origin: * 时，你不能将请求的 credentials 标志设置为 include。这意味着你不能在进行跨域请求时发送凭据（例如，cookies、HTTP authentication 或 client-side SSL certificates）。缺乏访问控制：使用 * 意味着你无法对访问你的资源的来源进行细粒度控制。你可能希望只允许特定的域访问你的资源，而不是所有的域。可能的性能问题：如果你的资源对外部访问量很大，那么允许所有的跨域请求可能会对服务器的性能产生影响。
2. JSONP（JSON with Padding）JSONP是一种通过动态创建script标签，实现跨域请求的方式。JSONP利用了script标签可以跨域访问的特性，通过指定callback参数，服务器端将返回数据包装成一个函数调用并返回给客户端，客户端再执行这个函数从而获取数据。		利用“src”不受同源策略约束的性质来实现跨域获取数据。使用$.getJSON()方法实现跨域请求，需要在请求路径URL后增加callback＝?, jQuery将自动替换“？”为正确的函数名，以执行回调函数。

​	**4.hash + iframe 只支持GET请求**

​	**5.postMessage 只支持GET请求**

​	**6.document.domain**

```
另外，通过给主域相同、二级域名不同的页面设置相同的document.domain，也可以解决cookie的跨域问题。Cookie 是服务器写入浏览器的一小段信息，只有同源的网页才能共享。但浏览器允许通过设置document.domain共享 Cookie。
```

1. **反向代理（Reverse Proxy)** 反向代理是一种网络服务，它接受客户端的请求，并将请求转发给后端服务器，然后将后端服务器的响应返回给客户端。与正向代理相反，正向代理是客户端代理服务器发送请求，反向代理是服务器代理客户端的请求。与前端页面同源，由他返回的数据就不存在跨域的问题，如图。 （备注：代理服务器与服务器之间是非同源，但不存在跨域问题，是因为服务器之间采用的是http请求，而不是ajax技术） 反向代理可以用于多种情况，例如：

​		负载均衡：反向代理可以将客户端请求分发到多个后端服务器上，从而平衡服务器的负载。		安全性：反向代理可以隐藏后端服务器的真实 IP 地址，从而提高服务器的安全性。		缓存：反向代理可以缓存静态资源，例如图片、样式文件等，从而减少服务器的负载。

​		常见的反向代理软件包括Nginx、Apache、HAProxy等。这些软件都具有高性能、高可靠性、高可定制性等特点，是构建高可用性和高性能系统的重要工具。

```js
// vue.config.js/webpack.config.js 
// 优点：可以配置多个代理，且可灵活控制请求是否走代理 
// 缺点：配置繁琐，发起代理请求时必须加上配置好的前缀
module.exports={
    devServer:{
        proxy:{
            '/api01':{
                target:'http://xxx.xxx.xxx:5000',
                changeOrigin:true,
                // 重写请求，根据接口详情，判断是否需要
                pathRewrite:{
                    '^/api01':''
                }
            }
// changeOrigin设置为true时，服务器收到的请求头的host与服务器地址相同
// changeOrigin设置为false时，服务器收到的请求头的host与前端地址相同
```

反向代理和正向代理：正向代理: 顺着请求的方向进行的代理，即代理服务器它是由你配置为你服务，去请求目标服务器地址。举例一: 如我们现在想要访问谷歌,但是由于某些原因,无法直接访问到谷歌,我们可以通过连接一台代理服务器,代理服务将我们的请求提交到谷歌,然后再将谷歌的响应反馈给我们,对于谷歌而言,它只知道有一个请求过来,但是它并不会知道我们是无法直接访问它的。作用如下：

1. 访问原来无法访问的资源，如google
2. 可以做缓存，加速访问资源
3. 对客户端访问授权，上网进行认证
4. 代理可以记录用户访问记录（上网行为管理），对外隐藏用户信息 反向代理: 跟正向代理相反,它是为目标服务器进行服务的,但是请求的流程还是: clieng -> proxy -> server。 举例: 比如我们访问百度网站，百度的代理服务器对外的域名为 https://www.baidu.com 。具体内部的服务器节点我们不知道。现实中我们通过访问百度的代理服务器后，代理服务器给我们转发请求到他们N多的服务器节点中的一个给我们进行搜索后将结果返回,此时,代理服务器对我们客户端来说就充当了提供响应的服务器,但是对于目标服务器来说,它只是进行了一个请求和转发的功能。
5. 保证内网的安全，阻止web攻击，大型网站，通常将反向代理作为公网访问地址，Web服务器是内网。
6. 负载均衡，通过反向代理服务器来优化网站的负载。

**在相同的域名中，可以共享以下几类数据：**

1. **Cookie**：Cookie是在浏览器中存储的小型数据文件，网站可以通过它们来存储用户信息（如用户名和密码），以便自动填充登录表单。这些文件是在用户的本地计算机上创建和存储的，并可以在同一域名下的所有页面之间共享。
2. **LocalStorage 和 SessionStorage**：这些是HTML5 Web Storage API的一部分，用于在用户的浏览器上存储数据。LocalStorage在浏览器会话之间保留数据，而SessionStorage则只在单个会话中保留数据。这些数据可以在同一域名下的所有页面之间共享。
3. **IndexedDB**：这是一种在浏览器中存储大量结构化数据的方法，例如，网站可以使用它来存储用户在离线状态下需要的数据。这些数据可以在同一域名下的所有页面之间共享。
4. **服务器端存储**：这种方法涉及将数据存储在服务器上，然后在需要时通过API调用获取。这些数据可以在同一域名下的所有页面之间共享。
5. **缓存**：浏览器缓存可以存储一些文件，例如样式表、脚本和图像，以便在浏览器下次加载页面时更快地加载它们。这些缓存的资源在同一域名下的所有页面间都可以被访问。

出于浏览器的同源策略（Same-Origin Policy），不同的域名（domain）默认情况下无法共享 cookie。这是出于安全考虑，避免跨站点请求伪造（CSRF）和其他安全威胁。然而，存在一些方法可以在一定程度上实现不同域名下的 cookie 共享：

1. **子域名之间的共享**：如果你有一个主域名（例如：example.com），并且有多个子域名（例如：sub1.example.com, sub2.example.com），你可以设置一个 cookie 的 domain 为主域名，这样所有的子域名都可以访问这个 cookie。在设置 cookie 时，将 domain 属性设置为 ".example.com"（注意前面有一个点）即可。
2. **通过服务器进行共享**：如果两个完全不同的域名（例如：example1.com 和 example2.com）想要共享 cookie，一种可能的方式是通过服务器进行中转。例如，example1.com 可以将某些数据发送到服务器，然后服务器将这些数据保存并发送到 example2.com。
3. **通过第三方 cookie 进行共享**：第三方 cookie 是由不是当前网站域的第三方设置的 cookie。例如，一个用户访问 example1.com，而页面中嵌入了 example2.com（如广告）的内容，example2.com 可以设置和读取第三方 cookie。然而，这种做法在很多情况下由于隐私问题而受到限制，许多现代浏览器默认情况下都禁用了第三方 cookie。

需要注意的是，跨域名共享 cookie 可能引发安全和隐私问题，因此在进行此类操作时需要谨慎，并确保遵守相关的法规政策。

参考：

​		https://zhuanlan.zhihu.com/p/104984869

https://developer.mozilla.org/zh-CN/docs/Web/HTTP/CORS

## 5.14 网站性能

```
	浏览器将页面从网络下载到本地后，主要做几个事情：解析HTML，创建DOM，同时加载依赖的资源：CSS、图片等（加载资源的过程不会阻塞DOM解析），然后调用渲染进程渲染到界面上。
```

​		这里需要注意一点，在现在浏览器中，为了减缓渲染被阻塞的情况，现代的浏览器都使用了猜测预加载。当解析被阻塞的时候，浏览器会有一个轻量级的HTML（或CSS）扫描器（scanner）继续在文档中扫描，查找那些将来可能能够用到的资源文件的url，在渲染器使用它们之前将其下载下来。在整个加载和渲染过程中会触发多个事件：

**白屏和首屏**

window.performance（API在IE9以上的浏览器）

白屏时间 = 地址栏输入网址后回车 - 浏览器出现第一个元素（window.firstPaint - window.pageStartTime） **白屏结束时间 = FP事件触发时间**

白屏时间是从用户开始请求页面时开始计算到开始显示内容结束，中间过程包括DNS查询、建立TCP链接、发送首个HTTP请求、返回HTML文档、HTML文档head解析完毕。

首屏时间 = 地址栏输入网址后回车 - 浏览器第一屏渲染完成（ window.firstScreen - window.pageStartTime） **首屏结束时间 = FCP事件触发时间或 FMP、LCP**

白屏常见的优化方案有：SSR、预渲染、骨架屏

优化首屏加载时间的方法：CDN分发（减少传输距离）、后端在业务层的缓存、静态文件缓存方案、前端的资源动态加载、减少请求的数量、利用好HTTP压缩

**load** (Onload Event)：DOM、图片、CSS、Flash等都加载完 (所有依赖的资源包括异步加载的资源，但不包括延时加载的资源)，`window.onload`注册的回调就会在load事件触发时候被调用。有时候**FCP比Onload Event先触发**，因为渲染第一个内容时候可能不包括图片的展示，只有文本内容。

**DCL**（DOMContentLoaded），DOM解析完毕。当 HTML 文档被完全加载和解析完成之后，DCL 事件被触发，无需等待样式表、图像和子框架的完成加载。可以通过注册回调监听该事件，如果需要**渲染的内容不多**，DCL在load之前，如果需要渲染的内容很多，那么DCL会在load之后。

**FP**（First Paint），表示渲染出第一个像素点。FP一般在HTML解析完成或者解析一部分时候触发。有节点不一定有渲染，如果没有任何样式，是没有界面的，也不需要渲染。渲染的操作一定是发**生在视口内**的，对于视口外不可见的内容不会渲染。

**FCP**（First Contentful Paint），表示渲染出第一个内容，这里的“内容”可以是文本、图片、canvas。

​	浏览器不一定等到所有的DOM都解析完再开始渲染，如果DOM节点少，浏览器会加载完再渲染，但是如果节点很多，浏览器解析一部分节点后就会开始渲染（这时候就会触发FP）。也就是说，当需要渲染的节点数少的时候，**DCL会在FP前面**；当需要渲染的节点数很多时候，DCL会在FP后面。

```js
const fcp = performance.getEntries('paint').filter(entry => entry.name == 'first-contentful-paint'）[0].startTime;
```

**FMP**（First Meaningful Paint），首次渲染有意义的内容的时间，将页面中最大布局变化后的第一次渲染事件作为FMP事件，并且计算中考虑到了可视区的因素。

**LCP**（largest contentful Paint），最大内容渲染时间。



参考：

https://zhuanlan.zhihu.com/p/495649475

https://zhuanlan.zhihu.com/p/82981365

https://blog.csdn.net/qq_41887214/article/details/130516839

## 5.15 加密

**对称加密**：对称加密又叫做私钥加密，即信息的发送方和接收方使用同一个密钥去加密和解密数据。对称加密的特点是算法公开、加密和解密速度快，适合于对大数据量进行加密。其加密过程中的私钥与解密过程中用到的私钥是同一个密钥，这也是称加密之所以称之为“对称”的原因

- 加密过程如下：明文 + 加密算法 + 私钥 => 密文
- 解密过程如下：密文 + 解密算法 + 私钥 => 明文

**非对称加密**也叫做公钥加密。其安全性更好。非对称加密使用一对密钥，即公钥和私钥，且二者成对出现。私钥被自己保存，不能对外泄露。公钥指的是公共的密钥，任何人都可以获得该密钥。用公钥或私钥中的任何一个进行加密，用另一个进行解密。

- 明文 + 加密算法 + 公钥 => 密文
- 密文 + 解密算法 + 私钥 => 明文

此外，还有一类 **不需要密钥** 的 **散列算法**。

常见的 对称加密 算法主要有 **DES、3DES、AES** 等，常见的 非对称算法 主要有 **RSA、ECC** 等，散列算法 主要有 **SHA-1、MD5** 等。

MD5 用的是 哈希函数，它的典型应用是对一段信息产生 信息摘要，以 防止被篡改。严格来说，MD5 不是一种 加密算法 而是 摘要算法。无论是多长的输入，MD5 都会输出长度为 128bits 的一个串 (通常用 16 进制 表示为 32 个字符)。RSA 加密算法是目前最有影响力的 公钥加密算法，并且被普遍认为是目前 最优秀的公钥方案 之一。RSA 是第一个能同时用于 加密 和 数字签名 的算法，它能够抵抗到目前为止已知的 所有密码攻击，已被 ISO 推荐为公钥数据加密标准。RSA 加密算法 基于一个十分简单的数论事实：将两个大 素数 相乘十分容易，但想要对其乘积进行 因式分解 却极其困难，因此可以将 乘积 公开作为 加密密钥。

1.**数字信封**。数字信封使用的是接收者的密钥对,用接收者的公 钥加密,只能由接收者的私钥解密,其实现过程为:

(1)信息发送者发送信息时,首先生成一个共享的对称密钥,用该 对称密钥加密要发送的明文,形成DES密文;

(2)信息发送者用接收者的公钥加密此对称密钥,形成密钥密文; (3)信息发送者将(1)和(2)的结果结合在一起,形成数字信封,一 并传给信息接收者。 信息接收者接到密文后,使用自己的私钥解密密钥密文,得到共享 的对称密钥;再用此对称密钥解密DES密文,得到真正的原始明文。 数字信封结合了非对称密钥算法安全性高和对称密钥算法速度快 的优点,数据在网络上是以密文形式传输的,保证了信息传输的机密 性,避免Internet上黑客窃取明文数据。

2.**数字签名**。数字签名使用的是发送者的密钥对,用发送者的私 钥加密,只能由发送者的公钥解密,其实现过程为:

(1)信息发送者使用单向Hash函数把明文生成一个定长的数字摘要。 单向Hash函数是单向不可逆的,采用相同的单向Hash函数,不同 的明文生成的数字摘要总是不同的,相同的明文其数字摘要必定一致, 数字摘要可用来验证数据传输的完整性。

(2)信息发送者使用自己的私钥加密数字摘要,形成数字签名。 (3)信息发送者把原始明文和数字签名一起发送给接收者。  接收者利用发送者的公钥对数字签名解密,得到数字摘要;同时对 收到的明文用同样的单向Hash函数产生一个数字摘要;将两个数字摘 要进行对比,如两者一致,说明传送过程中信息没有被破坏或篡改过。 数字签名不仅与签名者的私钥有关,而且与报文的内容有关,报文 不同,数字摘要一定不同,数字签名也不同,因此不能将签名者对一份 报文的签名复制到另一份报文上,能够防止报文的篡改,保证信息传输 的完整性。

1. 数字签名和数字信封都使用非对 称密钥算法,但实现过程相反,使用的密钥对不同。

(1)数字签名使用的是发送方的密钥对,发送方用自己的私钥进行 加密,接收方用发送方的公钥进行解密,这是一个一对多的关系,任何拥有发送方公钥的人都可以验证数字签名的正确性。

(2)数字信封使用的是接收方的密钥对,这是多对一的关系,任何知道接收方公钥的人都可以向接收方发送加密信息,只有惟一拥有接 收方私钥者才能对信息解密。

(3)数字签名只采用了非对称密钥加密算法和数字摘要技术,能够 保证发送信息的完整性;数字信封采用了对称密钥加密算法和非对称  密钥加密算法相结合的方法,能保证信息传输的机密性。

## 5.16 DNS

**域名系统**它作为将域名相互映射的一个分布式数据库，由 解析器 和 多个DNS服务器 组成的。

域名服务器是指保存有该网络中所有主机的域名和对应IP地址，并具有将域名转换为IP地址功能的服务器。

```
www(三级域名).baidu(二级域名).com(顶级域名).(根域名)
```

​		本地域名服务器是电脑解析时的**默认**域名服务器，即电脑中设置的首选 DNS 服务器和备选 DNS 服务器。

​		DNS服务器根据域名的层级，进行分级查询。所谓"分级查询"，就是从根域名开始，依次查询每一级域名的NS记录，直到查到最终的IP地址，分为迭代查询和递归查询。

​		为了缓解各个域名服务器的查询压力和加快 DNS 查询速度，浏览器、操作系统、域名服务器都会将 DNS 的查询结果进行缓存，当在缓存有效时间内再次收到重复的 DNS 请求时，就会直接返回 IP 地址，而不会继续下一步的域名查询了。缓存的优先级由 DNS 查询的路径来定，浏览器缓存>操作系统缓存> hosts 文件>本地DNS服务器缓存>根域名服务器缓存>...

​		缓存时间一般由 DNS响应报文 中 资源记录部分 中的 TTL (Time to live)指定的值，单位为秒

DNS 同时使用 TCP 和 UDP 协议的 53 号端口。这种单个应用协议同时使用两种传输协议的情况在 TCP/IP 栈也算是个另类。但很少有人知道 DNS 分别在什么情况下使用这两种协议。DNS 在 区域传输 （同步解析记录）和 DNS 响应大于 UDP 报文最大长度的时候使用 TCP 协议，其他时候使用 UDP 协议（快，是UDP的最大优势）。

**DNS查询的完整过程是怎么样的？**

浏览器将会检查缓存中有没有这个域名对应的解析过的 IP 地址，如果有该解析过程将会结束。浏览器缓存域名也是有限制的，包括缓存的时间、大小，可以通过 TTL 属性来设置。

如果用户的浏览器中缓存中没有，操作系统会先检查自己本地的 DNS 解析器缓存和 hosts 文件是否有这个网址映射关系，如果有，就先调用这个 IP 地址映射，完成域名解析。

如果都没有，会找 TCP/IP 参数中设置的首选 DNS 服务器，我们叫它本地 DNS 服务器。通过递归查询的方式向本地 DNS 服务器发起查询，如果本地 DNS 服务器中有 A记录 或者该域名的映射缓存，则返回

如果都没有，本地域名服务器会开始迭代查询的过程，会先向 13 台根域名服务器查询该域名，根域名服务器会返回该域名的顶级域名服务器的 IP 地址，也就是 NS 记录。然后本地域名服务器再向顶级域名服务器发起查询，顶级域名服务器返回二级域名服务器的 NS 记录，重复这个过程直到返回 A 记录为止，最后把 A 记录中的 IP 地址返回给主机

## 5.18 白屏问题

**从网络方面检测**

- 先确保网络连接顺畅
- 再检查 URL 地址是否错误
- 打开 控制台 查看是否有报错信息
- 查看接口访问 是否有请求
- 查看 路由 是否有 path错误 ，导致加载了不存在的页面

**从js和css方面检测**排除了 网络问题 以后，如果还是白屏，那一般都是 css和js 加载造成的；css和js 会造成阻塞渲染。比如不正确的引入css和js ， 就会导致它们的加载速度过长，从而导致白屏现象。正确的引入方式是：

```
在 <head> 标签中引入css：因为在加载HTML 前不先渲染css 的话，整个页面会乱掉；
在 </body> 标签之前、body 标签中html 内容的后面 ，引入 js：因为浏览器加载script 标签时，处理内部代码的顺序都是从上到下 依次执行的，如果在 html 内容前就引入js 的话，那么就会导致，在所有的代码处理完毕之前，会阻塞其他资源的加载；会导致页面的其他内容都无法显示，因此如果不规范引入js的话，会对页面的其他内容带来影响。
```

**从Dom渲染检测**

检测根节点是否渲染

Mutation Observer 监听 DOM 变化

​		快手检测方案原理很简单，当下主流的 SPA 框架，页面主体内容的 DOM 一般挂载在一个根节点下，例如` <div id="app"></div>`，当页面发生白屏时，对应的现象一般表现为根节点下的 DOM 被卸载或一开始就未渲染挂载过。所以，当检测到根节点下没有挂载 DOM 时可以认为当前是白屏状态，

​		最简单粗暴的方式便是通过轮询来检测，且不说对于页面性能的影响，仅是埋点上报数据的处理就有很大的成本，一方面数据量级不太可控，另一方面在这庞大的数据中，清洗出有效数据也得依赖数据团队支持，这在方案验证阶段几乎不太现实的；如果通过指定一些特定时机来检测，的确能避免轮询方案带来这些问题，但时机选择不合适对于方案的准确性也会带来影响，例如：

（1）时机过早，可能会将页面加载缓慢的 case 误判为白屏；

（2）时机过晚，可能还未检测用户已将页面关闭，从而出现漏判情况；

（3）页面加载完成后，可能某些用户操作背后的业务逻辑导致页面白屏情况，会被遗漏等。

因此，考虑到以上问题，最终引入了“白屏修正机制”，页面状态默认为白屏，然后通过一些时机来进行状态纠偏。具体如下：

​		进入页面后立即初始化页面为白屏，设置值为 result=0，监听 DOMContentLoaded【当 HTML 文档解析完成就会触发 DOMContentLoaded，而所有资源加载完成之后，load 事件才会被触发。】、beforeunload 事件，并通过 MutationObserver 监听 DOM 节点的变化，注意这两者间是并行处理的，两者间的交集只有页面的状态。只要 MutationObserver 检测到根节点有 DOM 变化，就会进行白屏感知检测，如果检测结果出现状态的切换，即白屏与非白屏的切换，就会更新状态值 result；而 DOMContentLoaded 和 beforeunload 事件主要被用于埋点上报。

​		最开始也有将 FCP 特性作为纠偏的一个重要指标，但是在回验阶段发现部分手机在白屏下仍会触发 FCP，所以只好暂时将该逻辑下线。

​		在「检测时机」中提到白屏感知依赖于 MutationObserver 监听 DOM 节点的变化，这里可能又会有疑问——为何不直接用 onerror 事件来做白屏感知的时机，在进行白屏检测的同时收集报错信息，并进行两者的关联，但这个前提是一切的白屏都是报错导致的，并均能被 onerror 事件捕获；即使可行，但这会将白屏检测和错误收集的逻辑耦合在一起。

​		使用 MutationObserver 监听目标节点，当有 DOM 变化时进行白屏感知——检测 DOM 节点是否渲染。

​		最初的想法是检测根节点（即<div id="app"></div>）下的元素长度，如果超过一定的阈值便认为是非白屏，明显这种检测过于粗糙；但如果对根节点下所有节点进行解析，逻辑较为复杂，多次触发检测对性能可能会有影响。

​		一般我们认为白屏表现为页面上没有任何内容，所以从这个角度出发，是不是只要检测到页面上有展示文本或图片即可认为当前是非白屏状态。因此检测感知做了一定优化：将根节点作为入口，进行深度优先遍历，在遍历过程中如果检测到有可见的文本或图片，即可认为当前为非白屏状态并可以立即结束遍历过程，如果遍历完所有节点仍未找到，即当前为白屏。

​		考虑到性能影响，在遍历过程中，如果某个父节点是不可见状态，便可退出当前树的遍历，跳到下一棵树，因为当前树的子节点以及后续节点均不可见；另外如果页面过于复杂，整个树的层级较深，也可以结合业务情况定制遍历的数的层级数。

​		当然为了保证检测结果更准确，也可以对树的节点分配权重，在遍历后计算权重总和，当超过一定阈值才界定为非白屏，这样可能需要在准确性和性能方面做一定取舍了。

埋点上报：

前文有提到 MutationObserver 和 DOM 事件并行，埋点上报的时机主要有以下四种：

（1）MutationObserver 检测到目标节点变化：

​	（a）状态从白屏状态切换为非白屏状态，仅更新状态数据，写入 localstorage，不进行上报，纠偏次数自增；

​	（b）状态从非白屏状态切换为白屏状态，立即进行上报并清除 localstorage 数据，纠偏次数自增；

（2）DOMContentLoaded 事件触发：白屏状态且纠偏次数为 0 和非白屏状态两种情况，立即进行上报并清除 localstorage 数据，其他情况不上报；

（3）beforeunload 事件触发：非白屏状态切纠偏次数与 DOMContentLoaded 事件上报的纠偏次数不一致时，立即进行上报并清除 localstorage 数据，其他情况不上报；

（4）下次进入页面：以防上次页面异常关闭未能及时上报数据，在下次进入页面时立即检查 localstorage 中是否存在白屏检测相关数据，存在则立即进行上报并清除 localstorage 数据。

通过 MutationObserver 检测机制保证白屏情况下数据立即上报的同时，也避免了重复数据的多次上报，而后三个时机对「检测时机」部分提到的一些边界情况，例如时机过早误判，过晚漏判等情况，进行了较好的补充。

「白屏感知」部分提到的白屏信息与错误信息关联问题的处理，需要依赖错误收集和 CDN 加载重试[插件](https://gw-c.nowcoder.com/api/sparta/jump/link?link=https%3A%2F%2Fkibt-log.test.gifshow.com%2Fconfig.html)上报的埋点，该插件能够比较详细地收集包括 js error、未捕获的 promise reject、console.error 和资源加载 error 等报错信息，白屏信息则可以通过埋点中的 radar_session_id 将两者进行关联。

**白屏优化**

- DNS解析优化针对DNS Lookup环节，我们可以针对性的进行DNS解析优化。
- DNS缓存优化
- DNS预加载策略
- 稳定可靠的DNS服务器
- TCP网络链路优化
- 服务端处理优化，对于大型网站，可以使用服务器端缓存，如使用Redis、Memcached等技术缓存数据；
- 减少DOM操作和重排操作，避免频繁改变页面结构和样式，提高页面渲染优化；
- 压缩代码：使用工具将 HTML、CSS、JS 等文件进行压缩，减小文件大小，加快加载速度。
- 合并文件：将多个小文件合并成一个大文件，减少浏览器请求次数，加快加载速度。
- 避免使用Flash或其它插件，因为它们会增加页面的加载时间和减缓页面的渲染；
- 将JavaScript脚本放到页面底部，减少页面的加载时间和渲染时间；
- 减小图片大小：使用图片压缩工具，将图片大小减小，减少加载时间。
- 延迟加载：将页面上不必要展示的图片、视频等资源延迟加载，减少首屏加载时间。
- 延迟加载：将页面上不必要展示的图片、视频等资源延迟加载，减少首屏加载时间。
- 优化网络请求：避免重定向、减少 HTTP 请求头大小、使用 HTTP/2 等技术优化网络请求，加快加载速度。

## 5.20 Storage

Web Storage 包含如下两种机制：

- sessionStorage 为每一个给定的源（given origin）维持一个独立的存储区域，该存储区域在页面会话期间可用（即只要浏览器处于打开状态，包括页面重新加载和恢复）。用于进行页面传值
- localStorage 同样的功能，但是在浏览器关闭，然后重新打开后数据仍然存在。用于存储适合长期保存在本地的数据、存储该浏览器对该页面的访问次数

作为 Web Storage API 的接口，Storage 提供了访问特定域名下的会话存储或本地存储的功能，例如，可以添加、修改或删除存储的数据项。**两者其实都拥有一个相同的原型对象 Storage。**

```
一些方法：
Storage.getItem() | key() | clear() | length只读 | setItem() | removeItem()
```

- 浏览器差异性可以通过storageAvailable('localStorage') === true判断
- 二者存储大小都是5MB
- 同源域名下面是可以共享 sessionStorage 的

**cookie和localStorage的区别：**

1. **生命周期**：`Cookie`的生命周期由其`Expires`或`Max-Age`属性决定，这些属性定义了`Cookie`的过期时间。如果不设置这些属性，`Cookie`则为`session`类型，会在用户关闭浏览器窗口后被删除。相比之下，`localStorage`数据没有过期时间，只有在用户手动清理浏览器数据或者使用 JavaScript 删除数据时，数据才会消失。
2. **存储容量**：`Cookie`的大小通常被限制在4KB左右，这对于大多数类型的数据都很小。`localStorage`的容量远大于`Cookie`，在大多数现代浏览器中，它可以存储5MB或更多的数据。
3. **与服务器的交互**：每次浏览器向服务器发送请求时，它都会自动附带`Cookie`，无论这些请求是否需要它。这可能会导致额外的流量，尤其是在`Cookie`非常大的情况下。相比之下，`localStorage`数据只在客户端使用，不会被自动发送到服务器。

**设置localStorage过期时间：**

直接使用 `xijs` 这个 `javascript` 工具库

在key-value上添加过期时间，比如("token"| 20min )，获取的时候判断是否过期，如果过期再去清除该项

**不同网站之间的存储可以互读吗**

​		另外，不同浏览器无法共享localStorage和sessionStorage中的信息。同一浏览器的相同域名和端口的不同页面间可以共享相同的 localStorage，但是不同页面间无法共享sessionStorage的信息。这里需要注意的是，页面仅指顶级窗口，如果一个页面包含多个iframe且他们属于同源页面，那么他们之间是可以共享sessionStorage的。`cookies` 的生命周期取决于设置的过期时间。如果设置了过期时间，那么在到达过期时间后，`cookies` 会被自动删除。如果没有设置过期时间，那么 `cookies` 会在浏览器关闭后被删除。但是，有一些浏览器可能会将这类 `cookies` 保留到浏览器完全关闭（包括所有的标签页和窗口）。

​		如何解决？目前广泛采用的是postMessage和iframe相结合的方法。postMessage(data,origin)方法允许来自不同源的脚本采用异步方式进行通信，可以实现跨文本档、多窗口、跨域消息传递。接受两个参数：

- data：要传递的数据，[HTML5](https://gw-c.nowcoder.com/api/sparta/jump/link?link=https%3A%2F%2Flink.jianshu.com%2F%3Ft%3Dhttp%3A%2F%2Flib.csdn.net%2Fbase%2Fhtml5)规范中提到该参数可以是[JavaScript](https://gw-c.nowcoder.com/api/sparta/jump/link?link=https%3A%2F%2Flink.jianshu.com%2F%3Ft%3Dhttp%3A%2F%2Flib.csdn.net%2Fbase%2Fjavascript)的任意基本类型或可复制的对象，然而并不是所有浏览器支持任意类型的参数，部分浏览器只能处理字符串参数，所以在传递参数时需要使用JSON.stringify()方法对对象参数序列化。
- origin：字符串参数，指明目标窗口的源，协议+主机+端口号[+URL]，URL会被忽略，所以可以不写，只是为了安全考虑，postMessage()方法只会将message传递给指定窗口，当然也可以将参数设置为"*"，这样可以传递给任意窗口，如果要指定和当前窗口同源的话设置为"/"。

**判断sessionStorage大小**

你可以使用以下的函数来估计 sessionStorage 的大小。这个函数的工作原理是遍历 sessionStorage 中的所有键值对，并计算它们的字节数。注意，这是一个近似值，实际的存储开销可能会因为浏览器的实现细节而略有不同。

```js
function sessionStorageSize() {
    let total = 0;
    for(let x in sessionStorage) {
        let amount = (sessionStorage[x].length * 2) / 1024 / 1024; // x.length * 2 是因为 sessionStorage 中的键和值都是以 UTF-16 格式存储的，每个字符占用 2 字节
        if (!isNaN(amount) && sessionStorage.hasOwnProperty(x)) {
            total += amount;
        }
    }
    return total.toFixed(2);
}

console.log(sessionStorageSize() + " MB");
```

## 5.21 标签间通信

1. **localStorage 和 sessionStorage：** 如果标签页都来自同一个域，它们可以通过共享localStorage 或者 sessionStorage 来进行通信。一个标签页可以写入数据，然后其他标签页可以读取或者监听改变事件来获取数据。
2. **BroadcastChannel API：** 这是一个比较新的浏览器API，允许来自同一源的不同窗口，标签页，Web Workers 或者 iframes 进行通信。你可以创建一个新的 BroadcastChannel 对象，然后使用 `postMessage` 方法发送消息，使用 `onmessage` 事件接收消息。
3. **Window.postMessage 方法：** 如果你有一个对其他标签页的 window 对象的引用，你可以使用 `postMessage` 方法发送消息。这常常用在主页面与打开的新窗口或者 iframe 之间的通信。
4. **共享 Web Worker：** Shared Worker 是一种可以由多个脚本，甚至是多个窗口，标签页，iframes 共享的Web Worker。
5. **服务端中继：** 如果前面的方法都不能使用，你可以考虑通过服务器进行中继。每个标签页可以向服务器发送信息，服务器再将这些信息广播给其他标签页。这可以通过 WebSocket，Server-Sent Events 或者轮询等技术实现。
6. **使用 cookies**：类似于 localStorage，你也可以使用 cookies 在页面间传递数据。但是，请注意 cookies 的大小限制（通常为 4KB）。
7. **通过 URL 参数**：这是一种简单的方法，页面 A 可以在 URL 中添加参数，然后在页面 B 中解析这些参数。例如，页面 A 可以使用 `window.location.href = 'http://example.com/pageB?param=value';` 来导航到页面 B，并传递参数。然后，页面 B 可以使用 JavaScript 来解析这些参数。

## 5.22 网站指标

1. **停留时间**

​		页面停留时间（Time on Page）简称 Tp，是网站分析中很常见的一个指标，用于反映用户在某些页面上停留时间的长短，传统的Tp统计方法会存在一定的统计盲区，比如无法监控单页应用，没有考虑用户切换Tab、最小化窗口等操作场景。基于上述背景，重新调研和实现了精确统计页面停留时长的方案，需要 兼容单页应用和多页应用，并且不耦合或入侵业务代码。

​		我们可以把一个页面生命周期抽象为三个动作：「进入」、「活跃状态切换」、「离开」

| 进入 | 首次加载，页面刷新，页面跳转，浏览器前进后退              |
| ---- | --------------------------------------------------------- |
| 切换 | 页面失去焦点/获得焦点，切换窗口最小化，切换 tab，电脑睡眠 |
| 离开 | 关闭页面，跳转页面，刷新，浏览器前进后退                  |

​		对于常规页面的 首次加载、页面关闭、刷新 等操作都可以通过 window.onload 和 window.onbeforeunload 事件来监听页面进入和离开，浏览器前进后退可以通过 pageshow 和 pagehide 处理。

- load / beforeunload
- pageshow / pagehide

对于单页应用内部的跳转可以转化为两个问题：

- 监听路由变化
- 判断变化的URL是否为不同页面 。

监听路由变化

​		目前主流的单页应用大部分都是基于 browserHistory (history api) 或者 hashHistory 来做路由处理，我们可以通过监听路由变化来判断页面是否有可能切换。注意是有可能切换，因为URL发生变化不代表页面一定切换，具体的路由配置是由业务决定的（既URL和页面的匹配规则）。browserHistory变化本质都会调用 History.pushState() 或 History.replaceState() ，能监听到这两个事件就能知道。通过 popstate 事件能解决一半问题，因为 popstate 只会在浏览器前进后退的时候触发，当调用 history.pushState() or history.replaceState() 的时候并不会触发。hashHistory 的实现是基于 hash 的变化，hash 的变化可以通过 hashchange 来监听

判断URL是否为不同页面

- 通过业务方在初始化的时候配置页面规则，然后JS通过URL匹配不同的规则来区分不同的页面。
- 每次URL发生变化就将数据上报，最终通过数据平台配置的页面URL规则来求和、过滤数据等

[#前端#]()[#前端面试#]()[#春招#]()



作者：夏目又三
链接：https://www.nowcoder.com/?type=818_1
来源：牛客网